{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa8ykQk92aLX"
      },
      "source": [
        "# Evaluation of RAG Using Ragas\n",
        "\n",
        "In the following notebook we'll explore how to evaluate RAG pipelines using a powerful open-source tool called \"Ragas\". This will give us tools to evaluate component-wise metrics, as well as end-to-end metrics about the performance of our RAG pipelines.\n",
        "\n",
        "In the following notebook we'll complete the following tasks:\n",
        "\n",
        "- 🤝 Breakout Room Part #1:\n",
        "  1. Install required libraries\n",
        "  2. Set Environment Variables\n",
        "  3. Creating a simple RAG pipeline with [LangChain v0.2.0](https://python.langchain.com/v0.2/docs/versions/v0_2/)\n",
        "  4. Synthetic Dataset Generation for Evaluation using the [Ragas](https://github.com/explodinggradients/ragas) framework.\n",
        "  \n",
        "\n",
        "- 🤝 Breakout Room Part #2:\n",
        "  1. Evaluating our pipeline with Ragas\n",
        "  3. Making Adjustments to our RAG Pipeline\n",
        "  4. Evaluating our Adjusted pipeline against our baseline\n",
        "  5. Testing OpenAI's Claim\n",
        "\n",
        "The only way to get started is to get started - so let's grab our dependencies for the day!\n",
        "\n",
        "> NOTE: Using this notebook as presented will occur a charge of ~$3USD from OpenAI usage. Most of this cost is produced by the Synthetic Data Generation step - if you want to reduce costs, please use the provided commented code to leverage `GPT-3.5-Turbo` as the `critic_llm`!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h4yh6f7q9uN"
      },
      "source": [
        "## Motivation\n",
        "\n",
        "A claim, made by OpenAI, is that their `text-embedding-3-small` is better (generally) than their `text-embedding-ada-002` model.\n",
        "\n",
        "Here's some passages from their [blog](https://openai.com/blog/new-embedding-models-and-api-updates) about the `text-embedding-3` release:\n",
        "\n",
        "> `text-embedding-3-small` is our new highly efficient embedding model and provides a significant upgrade over its predecessor, the `text-embedding-ada-002` model...\n",
        "\n",
        "> **Stronger performance.** Comparing `text-embedding-ada-002` to `text-embedding-3-small`, the average score on a commonly used benchmark for multi-language retrieval ([MIRACL](https://github.com/project-miracl/miracl)) has increased from 31.4% to 44.0%, while the average score on a commonly used benchmark for English tasks ([MTEB](https://github.com/embeddings-benchmark/mteb)) has increased from 61.0% to 62.3%.\n",
        "\n",
        "Well, with a library like Ragas - we can put that claim to the test!\n",
        "\n",
        "If what they claim is true - we should see an increase on related metrics by using the new embedding model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAH1znJ2pIp3"
      },
      "source": [
        "# 🤝 Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpkXAmMZpLhm"
      },
      "source": [
        "## Task 1: Installing Required Libraries\n",
        "\n",
        "A reminder that one of the [key features](https://blog.langchain.dev/langchain-v0-1-0/) of LangChain v0.1.0 is the compartmentalization of the various LangChain ecosystem packages!\n",
        "\n",
        "So let's begin grabbing all of our LangChain related packages!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BN13TZlSCv4",
        "outputId": "51d9c154-af83-42b2-ce72-9656729ecb9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -U -q langchain langchain-openai langchain_core langchain-community langchainhub openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm7gXsD6pqG0"
      },
      "source": [
        "We'll also get the \"star of the show\" today, which is Ragas!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvAvDNWBpjQ1",
        "outputId": "20ff8c89-11db-4071-b0a0-6b9bfc0e215f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9q6Z9oTpw3X"
      },
      "source": [
        "We'll be leveraging [QDrant](https://qdrant.tech/) again as our LangChain `VectorStore`.\n",
        "\n",
        "We'll also install `pymupdf` and its dependencies which will allow us to load PDFs using the `PyMuPDFLoader` in the `langchain-community` package!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAJK95napn8I",
        "outputId": "58f04109-385b-44c7-d3cb-4547d8acaea1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU qdrant-client pymupdf pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_C2JvG1qO3h"
      },
      "source": [
        "## Task 2: Set Environment Variables\n",
        "\n",
        "Let's set up our OpenAI API key so we can leverage their API later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Lhqp5rUThG-",
        "outputId": "97cb739d-66b4-4476-ca04-b6257004178f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from getpass import getpass\n",
        "\n",
        "openai.api_key = getpass(\"Please provide your OpenAI Key: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFbWNvo3rZ4H"
      },
      "source": [
        "## Task 3: Creating a Simple RAG Pipeline with LangChain v0.1.0\n",
        "\n",
        "Building on what we learned last week, we'll be leveraging LangChain v0.1.0 and LCEL to build a simple RAG pipeline that we can baseline with Ragas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV_BOewX8CW0"
      },
      "source": [
        "## Building our RAG pipeline\n",
        "\n",
        "Let's review the basic steps of RAG again:\n",
        "\n",
        "- Create an Index\n",
        "- Use retrieval to obtain pieces of context from our Index that are similar to our query\n",
        "- Use a LLM to generate responses based on the retrieved context\n",
        "\n",
        "Let's get started by creating our index.\n",
        "\n",
        "> NOTE: We're going to start leaning on the term \"index\" to refer to our `VectorStore`, `VectorDatabase`, etc. We can think of \"index\" as the catch-all term, whereas `VectorStore` and the like relate to the specific technologies used to create, store, and interact with the index."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VDGJdxCJEVc"
      },
      "source": [
        "### Creating an Index\n",
        "\n",
        "You'll notice that the largest changes (outside of some import changes) are that our old favourite chains are back to being bundled in an easily usable abstraction.\n",
        "\n",
        "We can still create custom chains using LCEL - but we can also be more confident that our pre-packaged chains are creating using LCEL under the hood."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmFFThawK8lO"
      },
      "source": [
        "#### Loading Data\n",
        "\n",
        "Let's start by loading some data!\n",
        "\n",
        "> NOTE: You'll notice that we're using a document loader from the community package of LangChain. This is part of the v0.2.0 changes that make the base (`langchain-core`) package remain lightweight while still providing access to some of the more powerful community integrations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DTDNFXaBSO2j"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "loader = PyMuPDFLoader(\n",
        "    \"https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf\",\n",
        ")\n",
        "\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3dJYlBCIX_p",
        "outputId": "1383c5b7-bb72-49ea-d323-fcd9eed48d60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf',\n",
              " 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf',\n",
              " 'page': 0,\n",
              " 'total_pages': 195,\n",
              " 'format': 'PDF 1.3',\n",
              " 'title': 'The Pmarca Blog Archives',\n",
              " 'author': '',\n",
              " 'subject': '',\n",
              " 'keywords': '',\n",
              " 'creator': '',\n",
              " 'producer': 'Mac OS X 10.10 Quartz PDFContext',\n",
              " 'creationDate': \"D:20150110020418Z00'00'\",\n",
              " 'modDate': \"D:20150110020418Z00'00'\",\n",
              " 'trapped': ''}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0].metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQUl3sbZK4_1"
      },
      "source": [
        "#### Transforming Data\n",
        "\n",
        "Now that we've got our single document - let's split it into smaller pieces so we can more effectively leverage it with our retrieval chain!\n",
        "\n",
        "We'll start with the classic: `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6Nt2E1xnLNgr"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 150,\n",
        "    chunk_overlap = 50\n",
        ")\n",
        "\n",
        "documents = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilzwQxhiLcVV"
      },
      "source": [
        "Let's confirm we've split our document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wRw6a4aLfWh",
        "outputId": "a707bbf6-6338-45fc-a75e-86d693dfe2c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2636"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ93HkYcMJwW"
      },
      "source": [
        "#### Loading OpenAI Embeddings Model\n",
        "\n",
        "We'll need a process by which we can convert our text into vectors that allow us to compare to our query vector.\n",
        "\n",
        "Let's use OpenAI's `text-embedding-ada-002` for this task!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JU6CrDVZMgKe"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-ada-002\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVtZR9JPLtR4"
      },
      "source": [
        "#### Creating a QDrant VectorStore\n",
        "\n",
        "Now that we have documents - we'll need a place to store them alongside their embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "978TWiCtMA0B"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "\n",
        "qdrant_vector_store = Qdrant.from_documents(\n",
        "    documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"PMarca Blogs\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk50NmrMDlWu"
      },
      "source": [
        "#### ❓ Question #1:\n",
        "\n",
        "List out a few of the techniques that Qdrant uses that make it performant.\n",
        "\n",
        "One general advantage that Qdrant has is its use of Rust, which is a particularly performant language. One of the more significant performance improvements comes from Qdrant's support for sparse vectors, which reduces the amount of stored vector data that needs to be generated to maintain a high fidelity representation of the source data. Additionally, a recent release introduced a new approach for indexing text data that removes the need for re-indexing immutable text fields. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ht6bJX9PAY"
      },
      "source": [
        "#### Creating a Retriever\n",
        "\n",
        "To complete our index, all that's left to do is expose our vectorstore as a retriever - which we can do the same way we would in previous version of LangChain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xne8P5dQTUiR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tags=['Qdrant', 'OpenAIEmbeddings'] vectorstore=<langchain_community.vectorstores.qdrant.Qdrant object at 0x10fa8fc50>\n"
          ]
        }
      ],
      "source": [
        "retriever = qdrant_vector_store.as_retriever()\n",
        "\n",
        "print(retriever)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO_DFBVKNvNm"
      },
      "source": [
        "#### Testing our Retriever\n",
        "\n",
        "Now that we've gone through the trouble of creating our retriever - let's see it in action!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "I9_ONxpnN0n6"
      },
      "outputs": [],
      "source": [
        "retrieved_documents = retriever.invoke(\"What is a rule of thumb for selecting an industry to invest in?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Za12yt4OBy1",
        "outputId": "6dfa1ae5-8198-49a1-b213-96b34a1a5147"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='Part 3: Where to go and why\n",
            "When picking an industry to enter, my favorite rule of thumb is\n",
            "this:' metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 124, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': '22e9f53c9d7f4f31be39f3267c48f093', '_collection_name': 'PMarca Blogs'}\n",
            "page_content='have a reasonable chance at succeeding.\n",
            "Second rule of thumb:\n",
            "Once you have picked an industry, get right to the center of it' metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 125, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': '95a3eb4319d84b55882e640273d6ad99', '_collection_name': 'PMarca Blogs'}\n",
            "page_content='are growing fast and changing rapidly.\n",
            "Also apply this rule when selecting which city to live in. Go to\n",
            "the city where all the action is happening.' metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 126, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': '74353fab4d9e49b382ca0759e98a5037', '_collection_name': 'PMarca Blogs'}\n",
            "page_content='growth companies.\n",
            "(This is not necessarily true in older and more established\n",
            "industries, but those aren’t the industries we’re talking about.)' metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 127, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': 'ae8c7d3873814dd19a92b2e160e6c686', '_collection_name': 'PMarca Blogs'}\n"
          ]
        }
      ],
      "source": [
        "for doc in retrieved_documents:\n",
        "  print(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8MKsT6JTgCU"
      },
      "source": [
        "### Creating a RAG Chain\n",
        "\n",
        "Now that we have the \"R\" in RAG taken care of - let's look at creating the \"AG\"!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs7qBLaEQEic"
      },
      "source": [
        "#### Creating a Prompt Template\n",
        "\n",
        "There are a few different ways we could create our prompt template - we could create a custom template, as seen in the code below, or we could simply pull a prompt from the prompt hub! Let's look at an example of that!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "eRCq_OKUQbKk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_variables=['context', 'input'] optional_variables=['chat_history'] input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]} partial_variables={'chat_history': []} metadata={'lc_hub_owner': 'langchain-ai', 'lc_hub_repo': 'retrieval-qa-chat', 'lc_hub_commit_hash': 'b60afb6297176b022244feb83066e10ecadcda7b90423654c4a9d45e7a73cebc'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template='Answer any use questions based solely on the context below:\\n\\n<context>\\n{context}\\n</context>')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))]\n"
          ]
        }
      ],
      "source": [
        "from langchain import hub\n",
        "\n",
        "retrieval_qa_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
        "\n",
        "print(retrieval_qa_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FziTftV5Q1H-",
        "outputId": "21189f0e-4b5d-4146-8071-eb0fff4a6f13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer any use questions based solely on the context below:\n",
            "\n",
            "<context>\n",
            "{context}\n",
            "</context>\n"
          ]
        }
      ],
      "source": [
        "print(retrieval_qa_prompt.messages[0].prompt.template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyq88IPFRGoT"
      },
      "source": [
        "As you can see - the prompt template is simple (and has a small error) - so we'll create our own to be a bit more specific!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ijSNkTAjTsep"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"Answer the question based only on the following context. If you cannot answer the question with the context, please respond with 'I don't know':\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYHnPaXl-cvJ"
      },
      "source": [
        "#### Setting Up our Basic QA Chain\n",
        "\n",
        "Now we can instantiate our basic RAG chain!\n",
        "\n",
        "We'll use LCEL directly just to see an example of it - but you could just as easily use an abstraction here to achieve the same goal!\n",
        "\n",
        "We'll also ensure to pass-through our context - which is critical for RAGAS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-TsjUWjbUfbW"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "primary_qa_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "retrieval_augmented_qa_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": prompt | primary_qa_llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MgAa9JwBuJx"
      },
      "source": [
        "#### 🏗️ Activity #1:\n",
        "\n",
        "Describe the pipeline shown above in simple terms. You can include a diagram if desired.\n",
        "\n",
        "Here's the flow of what's happening in the code block above:\n",
        "We're setting the LLM that should be used for this pipeline to be OpenAI's ChatGPT 3.5 Turbo. Next, we're setting up our RAG Q+A chain to take in and process the following information:\n",
        "- The question text is provided as part of the \"question\" context\n",
        "- The retriever is told to use that question as its context for searching for similar entities within the index\n",
        "- The question and the retriever are then collectively set as context for when the LLM is prompted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO69de-F-oMD"
      },
      "source": [
        "Let's test it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FS5NxC6UyU2",
        "outputId": "db9953a2-758d-4723-cd95-e980a47715d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The rule of thumb for selecting an industry to invest in is to pick an industry where you have a reasonable chance at succeeding.\n"
          ]
        }
      ],
      "source": [
        "question = \"What is a rule of thumb for selecting an industry to invest in?\"\n",
        "\n",
        "result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "\n",
        "print(result[\"response\"].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIuHVGPOO9P2",
        "outputId": "24ce3524-9284-4eea-f78b-4329a615d321"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I don't know.\n",
            "[Document(metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 17, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': '36b906ae077b4606bb9b2ac5611da7ca', '_collection_name': 'PMarca Blogs'}, page_content='other startups, and also diWerentiated from any large incum-\\nbents?\\nTiming risk — is it too early? Is it too late?'), Document(metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 124, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': '22e9f53c9d7f4f31be39f3267c48f093', '_collection_name': 'PMarca Blogs'}, page_content='Part 3: Where to go and why\\nWhen picking an industry to enter, my favorite rule of thumb is\\nthis:'), Document(metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 47, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': '8c3c717aa2874ecbb4f455840e8db9a1', '_collection_name': 'PMarca Blogs'}, page_content='more money.\\nSometimes investors are highly enthusiastic about funding new\\nbusinesses, and sometimes they’re just not.'), Document(metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 148, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': 'eeeb2e4205804311bea72a95fdbcbb4a', '_collection_name': 'PMarca Blogs'}, page_content='to swing for the fences and get rewarded for creating some-\\nthing new will go somewhere else, where they will receive stock')]\n"
          ]
        }
      ],
      "source": [
        "question = \"What did Pink Floyd have to say about how to proceed when investing in a new industry?\"\n",
        "\n",
        "result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "\n",
        "print(result[\"response\"].content)\n",
        "print(result[\"context\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-XYZueEP42k"
      },
      "source": [
        "We can already see that there are some improvements we could make here.\n",
        "\n",
        "For now, let's switch gears to RAGAS to see how we can leverage that tool to provide us insight into how our pipeline is performing!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOECHyzHRqDw"
      },
      "source": [
        "## Task 4: Synthetic Dataset Generation for Evaluation using Ragas\n",
        "\n",
        "Ragas is a powerful library that lets us evaluate our RAG pipeline by collecting input/output/context triplets and obtaining metrics relating to a number of different aspects of our RAG pipeline.\n",
        "\n",
        "We'll be evaluating on every core metric today, but in order to do that - we'll need to create a test set. Luckily for us, Ragas can do that directly!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqXQ0jweWJOu"
      },
      "source": [
        "### Synthetic Test Set Generation\n",
        "\n",
        "We can leverage Ragas' [`Synthetic Test Data generation`](https://docs.ragas.io/en/stable/concepts/testset_generation.html) functionality to generate our own synthetic QC pairs - as well as a synthetic ground truth - quite easily!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "nVk5SlU9znXe"
      },
      "outputs": [],
      "source": [
        "loader = PyMuPDFLoader(\n",
        "    \"https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf\",\n",
        ")\n",
        "\n",
        "eval_documents = loader.load()\n",
        "\n",
        "text_splitter_eval = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1200,\n",
        "    chunk_overlap = 50\n",
        ")\n",
        "\n",
        "eval_documents = text_splitter_eval.split_documents(eval_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7rOQkxhzrq3"
      },
      "source": [
        "#### ❓ Question #2:\n",
        "\n",
        "##### Why is it important to split our documents using different parameters when creating our synthetic data?\n",
        "This creates greater potential for variability in the resulting set of test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiAPYw-hz-zo",
        "outputId": "fc8c6829-5c53-4eb1-8407-1545f5a7d023"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "357"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(eval_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYCrVMW9Blda"
      },
      "source": [
        "\n",
        "> NOTE: 🛑 Using this notebook as presented will occur a charge of ~$3USD from OpenAI usage. Most of this cost is produced by the Synthetic Data Generation step - if you want to reduce costs, please use the provided commented code to leverage GPT-3.5-Turbo as the critic_llm. If you're attempting to create a lot of samples please be aware of cost, as well as rate limits. 🛑"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f75fdd56268a4b83a7fb7e4a3b2cce82",
            "1fb5a4b71deb406fa2f342c88b9e4e1d",
            "37ec9b5c847749439d7c155ac3b1ec68",
            "1317f4e20e1c4574a360345b427c3e8a",
            "2aa53858803d4ad39113009d86dd67fc",
            "7e1d22c19aff4c768d643c249e425d00",
            "3a498872a68049329b4d206629b9b3bf",
            "89a7c333d0b241169dc29ed998b2c9c4",
            "88c8557741734e59a6099bb5fa260f6e",
            "92ef10fab64c4f40a93da3d31b572016",
            "3b43c3f561e34d019007ac9a0125b28d",
            "05ab48866b5d49df9567ce9cbda5ee2e",
            "49c1ef316e404052a7c8528781db3f9a",
            "2dcb3e2fdf164e35a27a79cfae65933a",
            "202f4244384a4501bfc1ffa50af96a1f",
            "d93698b0506743ff98fdb998cfb7080a",
            "19acd28bfa2e4a7a83bc42faea5de770",
            "356b929fa8dc42538767c58dcce12217",
            "60a663f8736a43bcb47ac6c5f37ec597",
            "e6edc46811064de2b74a6a477c4a44b7",
            "a10a7577a99b4683a1d59a09d88f93a1",
            "444bc7dae1aa4e098b79655428599310"
          ]
        },
        "id": "IXc6sMglSej_",
        "outputId": "1d4904f0-9674-448a-9af3-f99da62cc8f3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2f619173bc141b1b8cfde24e728541b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "embedding nodes:   0%|          | 0/714 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Filename and doc_id are the same for all nodes.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "018a01bd5e204b4d93ad6be73e8f0cf4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>evolution_type</th>\n",
              "      <th>metadata</th>\n",
              "      <th>episode_done</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How do the roles and responsibilities of execu...</td>\n",
              "      <td>[from scratch. This is a sharp diWerence from ...</td>\n",
              "      <td>The roles and responsibilities of executives i...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How can internal confusion impact a startup's ...</td>\n",
              "      <td>[developing a large market, as opposed to Xght...</td>\n",
              "      <td>Internal confusion can impact a startup's stra...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How should founders approach market projection...</td>\n",
              "      <td>[Rethink this one from the ground up. Lots of ...</td>\n",
              "      <td>Founders should avoid saying they have no comp...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is Rachleff's Law of Startup Success and ...</td>\n",
              "      <td>[And when you have a great market, the team is...</td>\n",
              "      <td>Rachleff's Law of Startup Success states that ...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How can startups effectively hire, manage, pro...</td>\n",
              "      <td>[Contents\\nTHE PMARCA GUIDE TO STARTUPS\\nPart ...</td>\n",
              "      <td>Startups can effectively hire, manage, promote...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How can combining an MBA with another degree e...</td>\n",
              "      <td>[degree with an MBA. I’ll hire as many of thos...</td>\n",
              "      <td>Combining an MBA with another degree can enhan...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How does evolutionary behavior influence the D...</td>\n",
              "      <td>[Four: Doubt-Avoidance Tendency\\nThe brain of ...</td>\n",
              "      <td>Evolutionary behavior influences the Doubt-Avo...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What should you do when VCs say \"no\" to fundin...</td>\n",
              "      <td>[Part 2: When the VCs say \"no\"\\nThis post is a...</td>\n",
              "      <td>When VCs say 'no' to funding your startup, it ...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How can lack of curiosity be a danger to a sta...</td>\n",
              "      <td>[cated email desktop soaware, but rather the u...</td>\n",
              "      <td>Lack of curiosity can be a huge danger to a st...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How does not keeping a schedule benefit indivi...</td>\n",
              "      <td>[By not keeping a schedule, I mean: refuse to ...</td>\n",
              "      <td>The answer to given question is not present in...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How can targeted micromanagement help improve ...</td>\n",
              "      <td>[to Xx it, or…\\n(b) Intensively micromanage he...</td>\n",
              "      <td>Targeted micromanagement can help improve exec...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>How does email checking affect work quality?</td>\n",
              "      <td>[But what you’re really doing is fracturing yo...</td>\n",
              "      <td>Email checking affects work quality by fractur...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>How can a startup reduce timing risk to attrac...</td>\n",
              "      <td>[a signiXcantly higher market share than 2%. (...</td>\n",
              "      <td>To reduce timing risk and attract investors wh...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What benefits does a liberal arts undergrad de...</td>\n",
              "      <td>[world armed with an assault riGe instead of a...</td>\n",
              "      <td>The answer to given question is not present in...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>What boosts startup funding chances?</td>\n",
              "      <td>[Working backwards from that, the best thing y...</td>\n",
              "      <td>Having a working product that could be the fou...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>What signs indicate a young industry with pote...</td>\n",
              "      <td>[Part 3: Where to go and why\\nWhen picking an ...</td>\n",
              "      <td>If the founders of the major companies in an i...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>How do management and communication skills ben...</td>\n",
              "      <td>[The best way is to learn from a great manager...</td>\n",
              "      <td>Management and communication skills benefit yo...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>How do hiring process errors affect new hire s...</td>\n",
              "      <td>[then doesn’t know what the friend is currentl...</td>\n",
              "      <td>Hiring process errors can significantly impact...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Why focus on practical skills in college inste...</td>\n",
              "      <td>[Part 2: Skills and education\\n[Please read my...</td>\n",
              "      <td>Focusing on practical skills in college is imp...</td>\n",
              "      <td>reasoning</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>How should emails be categorized for follow-up...</td>\n",
              "      <td>[Emails that you know you’re going to have to ...</td>\n",
              "      <td>Emails that require follow-up reminders go int...</td>\n",
              "      <td>reasoning</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question  \\\n",
              "0   How do the roles and responsibilities of execu...   \n",
              "1   How can internal confusion impact a startup's ...   \n",
              "2   How should founders approach market projection...   \n",
              "3   What is Rachleff's Law of Startup Success and ...   \n",
              "4   How can startups effectively hire, manage, pro...   \n",
              "5   How can combining an MBA with another degree e...   \n",
              "6   How does evolutionary behavior influence the D...   \n",
              "7   What should you do when VCs say \"no\" to fundin...   \n",
              "8   How can lack of curiosity be a danger to a sta...   \n",
              "9   How does not keeping a schedule benefit indivi...   \n",
              "10  How can targeted micromanagement help improve ...   \n",
              "11       How does email checking affect work quality?   \n",
              "12  How can a startup reduce timing risk to attrac...   \n",
              "13  What benefits does a liberal arts undergrad de...   \n",
              "14               What boosts startup funding chances?   \n",
              "15  What signs indicate a young industry with pote...   \n",
              "16  How do management and communication skills ben...   \n",
              "17  How do hiring process errors affect new hire s...   \n",
              "18  Why focus on practical skills in college inste...   \n",
              "19  How should emails be categorized for follow-up...   \n",
              "\n",
              "                                             contexts  \\\n",
              "0   [from scratch. This is a sharp diWerence from ...   \n",
              "1   [developing a large market, as opposed to Xght...   \n",
              "2   [Rethink this one from the ground up. Lots of ...   \n",
              "3   [And when you have a great market, the team is...   \n",
              "4   [Contents\\nTHE PMARCA GUIDE TO STARTUPS\\nPart ...   \n",
              "5   [degree with an MBA. I’ll hire as many of thos...   \n",
              "6   [Four: Doubt-Avoidance Tendency\\nThe brain of ...   \n",
              "7   [Part 2: When the VCs say \"no\"\\nThis post is a...   \n",
              "8   [cated email desktop soaware, but rather the u...   \n",
              "9   [By not keeping a schedule, I mean: refuse to ...   \n",
              "10  [to Xx it, or…\\n(b) Intensively micromanage he...   \n",
              "11  [But what you’re really doing is fracturing yo...   \n",
              "12  [a signiXcantly higher market share than 2%. (...   \n",
              "13  [world armed with an assault riGe instead of a...   \n",
              "14  [Working backwards from that, the best thing y...   \n",
              "15  [Part 3: Where to go and why\\nWhen picking an ...   \n",
              "16  [The best way is to learn from a great manager...   \n",
              "17  [then doesn’t know what the friend is currentl...   \n",
              "18  [Part 2: Skills and education\\n[Please read my...   \n",
              "19  [Emails that you know you’re going to have to ...   \n",
              "\n",
              "                                         ground_truth evolution_type  \\\n",
              "0   The roles and responsibilities of executives i...         simple   \n",
              "1   Internal confusion can impact a startup's stra...         simple   \n",
              "2   Founders should avoid saying they have no comp...         simple   \n",
              "3   Rachleff's Law of Startup Success states that ...         simple   \n",
              "4   Startups can effectively hire, manage, promote...         simple   \n",
              "5   Combining an MBA with another degree can enhan...         simple   \n",
              "6   Evolutionary behavior influences the Doubt-Avo...         simple   \n",
              "7   When VCs say 'no' to funding your startup, it ...         simple   \n",
              "8   Lack of curiosity can be a huge danger to a st...         simple   \n",
              "9   The answer to given question is not present in...         simple   \n",
              "10  Targeted micromanagement can help improve exec...  multi_context   \n",
              "11  Email checking affects work quality by fractur...  multi_context   \n",
              "12  To reduce timing risk and attract investors wh...  multi_context   \n",
              "13  The answer to given question is not present in...  multi_context   \n",
              "14  Having a working product that could be the fou...  multi_context   \n",
              "15  If the founders of the major companies in an i...  multi_context   \n",
              "16  Management and communication skills benefit yo...  multi_context   \n",
              "17  Hiring process errors can significantly impact...  multi_context   \n",
              "18  Focusing on practical skills in college is imp...      reasoning   \n",
              "19  Emails that require follow-up reminders go int...      reasoning   \n",
              "\n",
              "                                             metadata  episode_done  \n",
              "0   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "1   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "2   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "3   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "4   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "5   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "6   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "7   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "8   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "9   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "10  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "11  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "12  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "13  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "14  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "15  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "16  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "17  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "18  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "19  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nest_asyncio\n",
        "import asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from ragas.testset.generator import TestsetGenerator\n",
        "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "# critic_llm = ChatOpenAI(model=\"gpt-3.5-turbo\") # <--- If you don't have GPT-4 access, or to reduce cost/rate limiting issues.\n",
        "critic_llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "generator = TestsetGenerator.from_langchain(\n",
        "    generator_llm,\n",
        "    critic_llm,\n",
        "    embeddings\n",
        ")\n",
        "\n",
        "distributions = {\n",
        "    simple: 0.5,\n",
        "    multi_context: 0.4,\n",
        "    reasoning: 0.1\n",
        "}\n",
        "\n",
        "testset = generator.generate_with_langchain_docs(eval_documents, 20, distributions, is_async = False)\n",
        "testset.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOIGT0XLz8ze"
      },
      "source": [
        "#### ❓ Question #3:\n",
        "\n",
        "`{simple: 0.5, reasoning: 0.25, multi_context: 0.25}`\n",
        "\n",
        "What exactly does this mapping refer to?\n",
        "- 50% of the questions that are generated should be simple and easy to answer based on the source content.\n",
        "- 25% of the questions should require some degree of reasoning from the LLM to be answered effectively.\n",
        "- 25% of the questions should require the LLM to incorporate multiple pieces of context from the source data to be answered correctly.\n",
        "\n",
        "> NOTE: Check out the Ragas documentation on this generation process [here](https://docs.ragas.io/en/stable/concepts/testset_generation.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MemL406rUzBu"
      },
      "source": [
        "Let's look at the output and see what we can learn about it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaCDdImVU15s",
        "outputId": "31efbb94-f09d-4d50-8c6e-59202aaeb5c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataRow(question='How do the roles and responsibilities of executives in big companies differ from those in startups?', contexts=['from scratch. This is a sharp diWerence from many big\\ncompany executives, who can spend their entire careers\\nrunning organizations other people built — oaen years or\\ndecades earlier.\\n•\\nBe a primary individual contributor– a startup executive\\nmust “roll up her sleeves” and produce output herself. There\\nare no shortage of critical things to be done at a startup, and\\nan executive who cannot personally produce while\\nsimultaneously building and running her organization\\ntypically will not last long. Again, this is a sharp diWerence\\nfrom many big companies, where executives oaen serve\\nmore as administrators and bureaucrats.\\n•\\nBe a team player– a startup executive must take personal\\nresponsibility for her relationships with her peers and people\\nthroughout the startup, in all functions and at all levels. Big\\ncompanies can oaen tolerate internal rivalries and warfare;\\nstartups cannot.\\nBeing a startup executive is not an easy job. The rewards are\\nsubstantial — the ability to contribute directly to the startups’s\\nsuccess; the latitude to build and run an organization according\\nto her own theories and principles; and a meaningful equity'], ground_truth='The roles and responsibilities of executives in big companies often involve running organizations built by others, serving more as administrators and bureaucrats, and tolerating internal rivalries and warfare. In contrast, startup executives are primary individual contributors, must personally produce output, and take personal responsibility for relationships with peers and people throughout the startup.', evolution_type='simple', metadata=[{'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 59, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': ''}])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testset.test_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrPsVwUAWFWB"
      },
      "source": [
        "### Generating Responses with RAG Pipeline\n",
        "\n",
        "Now that we have some QC pairs, and some ground truths, let's evaluate our RAG pipeline using Ragas.\n",
        "\n",
        "The process is, again, quite straightforward - thanks to Ragas and LangChain!\n",
        "\n",
        "Let's start by extracting our questions and ground truths from our create testset.\n",
        "\n",
        "We can start by converting our test dataset into a Pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "frvzu1YxX8kY"
      },
      "outputs": [],
      "source": [
        "test_df = testset.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GFKMIY8IZU8m",
        "outputId": "ed137f4f-df2c-41fa-d868-802d30076ea0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>evolution_type</th>\n",
              "      <th>metadata</th>\n",
              "      <th>episode_done</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How do the roles and responsibilities of execu...</td>\n",
              "      <td>[from scratch. This is a sharp diWerence from ...</td>\n",
              "      <td>The roles and responsibilities of executives i...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How can internal confusion impact a startup's ...</td>\n",
              "      <td>[developing a large market, as opposed to Xght...</td>\n",
              "      <td>Internal confusion can impact a startup's stra...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How should founders approach market projection...</td>\n",
              "      <td>[Rethink this one from the ground up. Lots of ...</td>\n",
              "      <td>Founders should avoid saying they have no comp...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is Rachleff's Law of Startup Success and ...</td>\n",
              "      <td>[And when you have a great market, the team is...</td>\n",
              "      <td>Rachleff's Law of Startup Success states that ...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How can startups effectively hire, manage, pro...</td>\n",
              "      <td>[Contents\\nTHE PMARCA GUIDE TO STARTUPS\\nPart ...</td>\n",
              "      <td>Startups can effectively hire, manage, promote...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How can combining an MBA with another degree e...</td>\n",
              "      <td>[degree with an MBA. I’ll hire as many of thos...</td>\n",
              "      <td>Combining an MBA with another degree can enhan...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How does evolutionary behavior influence the D...</td>\n",
              "      <td>[Four: Doubt-Avoidance Tendency\\nThe brain of ...</td>\n",
              "      <td>Evolutionary behavior influences the Doubt-Avo...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What should you do when VCs say \"no\" to fundin...</td>\n",
              "      <td>[Part 2: When the VCs say \"no\"\\nThis post is a...</td>\n",
              "      <td>When VCs say 'no' to funding your startup, it ...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How can lack of curiosity be a danger to a sta...</td>\n",
              "      <td>[cated email desktop soaware, but rather the u...</td>\n",
              "      <td>Lack of curiosity can be a huge danger to a st...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How does not keeping a schedule benefit indivi...</td>\n",
              "      <td>[By not keeping a schedule, I mean: refuse to ...</td>\n",
              "      <td>The answer to given question is not present in...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How can targeted micromanagement help improve ...</td>\n",
              "      <td>[to Xx it, or…\\n(b) Intensively micromanage he...</td>\n",
              "      <td>Targeted micromanagement can help improve exec...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>How does email checking affect work quality?</td>\n",
              "      <td>[But what you’re really doing is fracturing yo...</td>\n",
              "      <td>Email checking affects work quality by fractur...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>How can a startup reduce timing risk to attrac...</td>\n",
              "      <td>[a signiXcantly higher market share than 2%. (...</td>\n",
              "      <td>To reduce timing risk and attract investors wh...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What benefits does a liberal arts undergrad de...</td>\n",
              "      <td>[world armed with an assault riGe instead of a...</td>\n",
              "      <td>The answer to given question is not present in...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>What boosts startup funding chances?</td>\n",
              "      <td>[Working backwards from that, the best thing y...</td>\n",
              "      <td>Having a working product that could be the fou...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>What signs indicate a young industry with pote...</td>\n",
              "      <td>[Part 3: Where to go and why\\nWhen picking an ...</td>\n",
              "      <td>If the founders of the major companies in an i...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>How do management and communication skills ben...</td>\n",
              "      <td>[The best way is to learn from a great manager...</td>\n",
              "      <td>Management and communication skills benefit yo...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>How do hiring process errors affect new hire s...</td>\n",
              "      <td>[then doesn’t know what the friend is currentl...</td>\n",
              "      <td>Hiring process errors can significantly impact...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Why focus on practical skills in college inste...</td>\n",
              "      <td>[Part 2: Skills and education\\n[Please read my...</td>\n",
              "      <td>Focusing on practical skills in college is imp...</td>\n",
              "      <td>reasoning</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>How should emails be categorized for follow-up...</td>\n",
              "      <td>[Emails that you know you’re going to have to ...</td>\n",
              "      <td>Emails that require follow-up reminders go int...</td>\n",
              "      <td>reasoning</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question  \\\n",
              "0   How do the roles and responsibilities of execu...   \n",
              "1   How can internal confusion impact a startup's ...   \n",
              "2   How should founders approach market projection...   \n",
              "3   What is Rachleff's Law of Startup Success and ...   \n",
              "4   How can startups effectively hire, manage, pro...   \n",
              "5   How can combining an MBA with another degree e...   \n",
              "6   How does evolutionary behavior influence the D...   \n",
              "7   What should you do when VCs say \"no\" to fundin...   \n",
              "8   How can lack of curiosity be a danger to a sta...   \n",
              "9   How does not keeping a schedule benefit indivi...   \n",
              "10  How can targeted micromanagement help improve ...   \n",
              "11       How does email checking affect work quality?   \n",
              "12  How can a startup reduce timing risk to attrac...   \n",
              "13  What benefits does a liberal arts undergrad de...   \n",
              "14               What boosts startup funding chances?   \n",
              "15  What signs indicate a young industry with pote...   \n",
              "16  How do management and communication skills ben...   \n",
              "17  How do hiring process errors affect new hire s...   \n",
              "18  Why focus on practical skills in college inste...   \n",
              "19  How should emails be categorized for follow-up...   \n",
              "\n",
              "                                             contexts  \\\n",
              "0   [from scratch. This is a sharp diWerence from ...   \n",
              "1   [developing a large market, as opposed to Xght...   \n",
              "2   [Rethink this one from the ground up. Lots of ...   \n",
              "3   [And when you have a great market, the team is...   \n",
              "4   [Contents\\nTHE PMARCA GUIDE TO STARTUPS\\nPart ...   \n",
              "5   [degree with an MBA. I’ll hire as many of thos...   \n",
              "6   [Four: Doubt-Avoidance Tendency\\nThe brain of ...   \n",
              "7   [Part 2: When the VCs say \"no\"\\nThis post is a...   \n",
              "8   [cated email desktop soaware, but rather the u...   \n",
              "9   [By not keeping a schedule, I mean: refuse to ...   \n",
              "10  [to Xx it, or…\\n(b) Intensively micromanage he...   \n",
              "11  [But what you’re really doing is fracturing yo...   \n",
              "12  [a signiXcantly higher market share than 2%. (...   \n",
              "13  [world armed with an assault riGe instead of a...   \n",
              "14  [Working backwards from that, the best thing y...   \n",
              "15  [Part 3: Where to go and why\\nWhen picking an ...   \n",
              "16  [The best way is to learn from a great manager...   \n",
              "17  [then doesn’t know what the friend is currentl...   \n",
              "18  [Part 2: Skills and education\\n[Please read my...   \n",
              "19  [Emails that you know you’re going to have to ...   \n",
              "\n",
              "                                         ground_truth evolution_type  \\\n",
              "0   The roles and responsibilities of executives i...         simple   \n",
              "1   Internal confusion can impact a startup's stra...         simple   \n",
              "2   Founders should avoid saying they have no comp...         simple   \n",
              "3   Rachleff's Law of Startup Success states that ...         simple   \n",
              "4   Startups can effectively hire, manage, promote...         simple   \n",
              "5   Combining an MBA with another degree can enhan...         simple   \n",
              "6   Evolutionary behavior influences the Doubt-Avo...         simple   \n",
              "7   When VCs say 'no' to funding your startup, it ...         simple   \n",
              "8   Lack of curiosity can be a huge danger to a st...         simple   \n",
              "9   The answer to given question is not present in...         simple   \n",
              "10  Targeted micromanagement can help improve exec...  multi_context   \n",
              "11  Email checking affects work quality by fractur...  multi_context   \n",
              "12  To reduce timing risk and attract investors wh...  multi_context   \n",
              "13  The answer to given question is not present in...  multi_context   \n",
              "14  Having a working product that could be the fou...  multi_context   \n",
              "15  If the founders of the major companies in an i...  multi_context   \n",
              "16  Management and communication skills benefit yo...  multi_context   \n",
              "17  Hiring process errors can significantly impact...  multi_context   \n",
              "18  Focusing on practical skills in college is imp...      reasoning   \n",
              "19  Emails that require follow-up reminders go int...      reasoning   \n",
              "\n",
              "                                             metadata  episode_done  \n",
              "0   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "1   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "2   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "3   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "4   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "5   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "6   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "7   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "8   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "9   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "10  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "11  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "12  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "13  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "14  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "15  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "16  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "17  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "18  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "19  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  "
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "xAiXbVmLYSoC"
      },
      "outputs": [],
      "source": [
        "test_questions = test_df[\"question\"].values.tolist()\n",
        "test_groundtruths = test_df[\"ground_truth\"].values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aE5rfMLfbqKH"
      },
      "source": [
        "Now we'll generate responses using our RAG pipeline using the questions we've generated - we'll also need to collect our retrieved contexts for each question.\n",
        "\n",
        "We'll do this in a simple loop to see exactly what's happening!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "9_AayvT1dAQN"
      },
      "outputs": [],
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "  answers.append(response[\"response\"].content)\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opHaHmYDeBfC"
      },
      "source": [
        "Now we can wrap our information in a Hugging Face dataset for use in the Ragas library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "fY48YZITeHy-"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "response_dataset = Dataset.from_dict({\n",
        "    \"question\" : test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : test_groundtruths\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmeVvQaZeogE"
      },
      "source": [
        "Let's take a peek and see what that looks like!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOpydvc8eqNM",
        "outputId": "f924b59d-eb6b-4c1a-9d18-f545c4e2c724"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'How do the roles and responsibilities of executives in big companies differ from those in startups?',\n",
              " 'answer': 'Executives in big companies require different skill sets compared to executives in startups.',\n",
              " 'contexts': ['are very Even great big company executives frequently\\nhave no idea what to do once they arrive at a startup.\\n•',\n",
              "  'will succeed without you.\\n•\\nBeware hiring a big company executive for a startup.The\\nexecutive skill sets required for a big company vs a startup',\n",
              "  'how to hire, manage, promote, and Xre executives in a startup\\nbased on my personal observations and experiences.',\n",
              "  'up and comer at a midsized company but wants a shot at\\nbeing a primary executive at a startup can be a great catch.\\n•'],\n",
              " 'ground_truth': 'The roles and responsibilities of executives in big companies often involve running organizations built by others, serving more as administrators and bureaucrats, and tolerating internal rivalries and warfare. In contrast, startup executives are primary individual contributors, must personally produce output, and take personal responsibility for relationships with peers and people throughout the startup.'}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM4fmAnsBmL2"
      },
      "source": [
        "# 🤝 Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbsFm5FievJI"
      },
      "source": [
        "## Task 1: Evaluating our Pipeline with Ragas\n",
        "\n",
        "Now that we have our response dataset - we can finally get into the \"meat\" of Ragas - evaluation!\n",
        "\n",
        "First, we'll import the desired metrics, then we can use them to evaluate our created dataset!\n",
        "\n",
        "Check out the specific metrics we'll be using in the Ragas documentation:\n",
        "\n",
        "- [Faithfulness](https://docs.ragas.io/en/stable/concepts/metrics/faithfulness.html)\n",
        "- [Answer Relevancy](https://docs.ragas.io/en/stable/concepts/metrics/answer_relevance.html)\n",
        "- [Context Precision](https://docs.ragas.io/en/stable/concepts/metrics/context_precision.html)\n",
        "- [Context Recall](https://docs.ragas.io/en/stable/concepts/metrics/context_recall.html)\n",
        "- [Answer Correctness](https://docs.ragas.io/en/stable/concepts/metrics/answer_correctness.html)\n",
        "\n",
        "See the accompanied presentation for more in-depth explanations about each of the metrics!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "R2PXwyt8e5aW"
      },
      "outputs": [],
      "source": [
        "from ragas import evaluate\n",
        "from ragas.metrics import (\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    answer_correctness,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        ")\n",
        "\n",
        "metrics = [\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        "    answer_correctness,\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx-vlsx_hrtV"
      },
      "source": [
        "All that's left to do is call \"evaluate\" and away we go!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "32514310070a426ea247c9f1bc66b630",
            "3e7520df71de40e0af5589b6aeb95171",
            "05390d20f1b445b5b02529ee7a99f6d6",
            "3380693903474d2585638f7e3458fcd6",
            "1d43002974f24e8a8b6961cddc04ce47",
            "97abe811c89c44dcacd7e39074d22546",
            "87a3d4b2ed5f4f1ca895c6a1981eb847",
            "589c2004f5504a239615dec8671785d0",
            "25d3337c457f4c748ed8bf78f5a27fe8",
            "31064d2adec14238a609d3f9791c64f3",
            "4f482b8ce7a54c1787394fb7d90391a0"
          ]
        },
        "id": "DhlcfJ4lgYVI",
        "outputId": "85fa2a99-7506-45d1-a674-ca9f55372264"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f00f2d8813840c59ce327a1f73859ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1589, in _request\n",
            "    response.raise_for_status()\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_models.py\", line 761, in raise_for_status\n",
            "    raise HTTPStatusError(message, request=request, response=self)\n",
            "httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'\n",
            "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_precision.py\", line 161, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 58, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 110, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 78, in inner\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/__init__.py\", line 390, in <lambda>\n",
            "    self._add_action_func(lambda rs: rs.outcome.result())\n",
            "                                     ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 61, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 170, in agenerate_text\n",
            "    return await self.langchain_llm.agenerate_prompt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 723, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 649, in agenerate\n",
            "    results = await asyncio.gather(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 316, in __step_run_and_handle_result\n",
            "    result = coro.throw(exc)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 868, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 674, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1514, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1595, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1641, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1595, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1639, in _retry_request\n",
            "    await anyio.sleep(timeout)\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/anyio/_core/_eventloop.py\", line 86, in sleep\n",
            "    return await get_async_backend().sleep(delay)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 2045, in sleep\n",
            "    await sleep(delay)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1589, in _request\n",
            "    response.raise_for_status()\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_models.py\", line 761, in raise_for_status\n",
            "    raise HTTPStatusError(message, request=request, response=self)\n",
            "httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'\n",
            "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 58, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 110, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 78, in inner\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/__init__.py\", line 390, in <lambda>\n",
            "    self._add_action_func(lambda rs: rs.outcome.result())\n",
            "                                     ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 61, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 170, in agenerate_text\n",
            "    return await self.langchain_llm.agenerate_prompt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 723, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 649, in agenerate\n",
            "    results = await asyncio.gather(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 316, in __step_run_and_handle_result\n",
            "    result = coro.throw(exc)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 868, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 674, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1514, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1595, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1639, in _retry_request\n",
            "    await anyio.sleep(timeout)\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/anyio/_core/_eventloop.py\", line 86, in sleep\n",
            "    return await get_async_backend().sleep(delay)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 2045, in sleep\n",
            "    await sleep(delay)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_precision.py\", line 161, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "No statements were generated from the answer.\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 58, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 110, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 78, in inner\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/__init__.py\", line 390, in <lambda>\n",
            "    self._add_action_func(lambda rs: rs.outcome.result())\n",
            "                                     ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 61, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 170, in agenerate_text\n",
            "    return await self.langchain_llm.agenerate_prompt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 723, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 649, in agenerate\n",
            "    results = await asyncio.gather(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 868, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 674, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1514, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1595, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1641, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1595, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1641, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1548, in _request\n",
            "    response = await self._client.send(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1661, in send\n",
            "    response = await self._send_handling_auth(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1689, in _send_handling_auth\n",
            "    response = await self._send_handling_redirects(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1726, in _send_handling_redirects\n",
            "    response = await self._send_single_request(request)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1763, in _send_single_request\n",
            "    response = await transport.handle_async_request(request)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 373, in handle_async_request\n",
            "    resp = await self._pool.handle_async_request(req)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 216, in handle_async_request\n",
            "    raise exc from None\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 196, in handle_async_request\n",
            "    response = await connection.handle_async_request(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/connection.py\", line 101, in handle_async_request\n",
            "    return await self._connection.handle_async_request(request)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 143, in handle_async_request\n",
            "    raise exc\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 113, in handle_async_request\n",
            "    ) = await self._receive_response_headers(**kwargs)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 186, in _receive_response_headers\n",
            "    event = await self._receive_event(timeout=timeout)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 224, in _receive_event\n",
            "    data = await self._network_stream.read(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
            "    return await self._stream.receive(max_bytes=max_bytes)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/anyio/streams/tls.py\", line 205, in receive\n",
            "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/anyio/streams/tls.py\", line 147, in _call_sslobject_method\n",
            "    data = await self.transport_stream.receive()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 1133, in receive\n",
            "    await self._protocol.read_event.wait()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
            "    await fut\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n"
          ]
        }
      ],
      "source": [
        "results = evaluate(response_dataset, metrics, raise_exceptions=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqPArpSrgwDD",
        "outputId": "e8f3cb2f-8a38-47a5-f54d-ec80eaca8448"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.6974, 'answer_relevancy': 0.8978, 'context_recall': 0.5972, 'context_precision': 0.7191, 'answer_correctness': 0.4019}"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2nsGzj8DhP9E",
        "outputId": "a10d6394-0ab7-48bf-96c5-acfc5992622f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>answer_correctness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How do the roles and responsibilities of execu...</td>\n",
              "      <td>Executives in big companies require different ...</td>\n",
              "      <td>[are very Even great big company executives fr...</td>\n",
              "      <td>The roles and responsibilities of executives i...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.957546</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How can internal confusion impact a startup's ...</td>\n",
              "      <td>Internal confusion can impact a startup's stra...</td>\n",
              "      <td>[ing about competitors.\\nI see two destructive...</td>\n",
              "      <td>Internal confusion can impact a startup's stra...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.998546</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.455320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How should founders approach market projection...</td>\n",
              "      <td>Founders should approach market projections ca...</td>\n",
              "      <td>[ularly true for startups that have not yet ac...</td>\n",
              "      <td>Founders should avoid saying they have no comp...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.969808</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.519414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is Rachleff's Law of Startup Success and ...</td>\n",
              "      <td>Rachleff's Law of Startup Success emphasizes t...</td>\n",
              "      <td>[Law of Startup Success:\\nT\\nThe #1 compan\\nhe...</td>\n",
              "      <td>Rachleff's Law of Startup Success states that ...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.950218</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.579109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How can startups effectively hire, manage, pro...</td>\n",
              "      <td>Startups can effectively hire, manage, promote...</td>\n",
              "      <td>[how to hire, manage, promote, and Xre executi...</td>\n",
              "      <td>Startups can effectively hire, manage, promote...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.934386</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How can combining an MBA with another degree e...</td>\n",
              "      <td>Combining an MBA with another degree can be a ...</td>\n",
              "      <td>[bly can.\\nAn MBA plus a law degree can be a g...</td>\n",
              "      <td>Combining an MBA with another degree can enhan...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.872958</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How does evolutionary behavior influence the D...</td>\n",
              "      <td>Evolutionary behavior influences the Doubt-Avo...</td>\n",
              "      <td>[Four: Doubt-Avoidance Tendency\\nThe brain of ...</td>\n",
              "      <td>Evolutionary behavior influences the Doubt-Avo...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.949224</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What should you do when VCs say \"no\" to fundin...</td>\n",
              "      <td>Meeting with more VCs after a bunch have said ...</td>\n",
              "      <td>[Part 2: When the VCs say \"no\"\\nThis post is a...</td>\n",
              "      <td>When VCs say 'no' to funding your startup, it ...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.937992</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How can lack of curiosity be a danger to a sta...</td>\n",
              "      <td>Lack of curiosity can be a huge danger to a st...</td>\n",
              "      <td>[the importance of hiring curious people — is ...</td>\n",
              "      <td>Lack of curiosity can be a huge danger to a st...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.852250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.405544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How does not keeping a schedule benefit indivi...</td>\n",
              "      <td>Not keeping a schedule benefits individuals in...</td>\n",
              "      <td>[By not keeping a schedule, I mean: refuse to ...</td>\n",
              "      <td>The answer to given question is not present in...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.179815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How can targeted micromanagement help improve ...</td>\n",
              "      <td>Targeted micromanagement can help improve exec...</td>\n",
              "      <td>[SpeciXcally, there are times and situations w...</td>\n",
              "      <td>Targeted micromanagement can help improve exec...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>How does email checking affect work quality?</td>\n",
              "      <td>Email checking can disrupt work quality by int...</td>\n",
              "      <td>[address to anyone noncritical — including you...</td>\n",
              "      <td>Email checking affects work quality by fractur...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.971018</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>How can a startup reduce timing risk to attrac...</td>\n",
              "      <td>A startup can reduce timing risk by taking ste...</td>\n",
              "      <td>[other startups, and also diWerentiated from a...</td>\n",
              "      <td>To reduce timing risk and attract investors wh...</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.946388</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What benefits does a liberal arts undergrad de...</td>\n",
              "      <td>The benefits of a liberal arts undergrad degre...</td>\n",
              "      <td>[liberal arts broadening your horizons.\\nWhat ...</td>\n",
              "      <td>The answer to given question is not present in...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.991984</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.177634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>What boosts startup funding chances?</td>\n",
              "      <td>Having the right founding team boosts startup ...</td>\n",
              "      <td>[Xrst place. What if you have a startup for wh...</td>\n",
              "      <td>Having a working product that could be the fou...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.912488</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>What signs indicate a young industry with pote...</td>\n",
              "      <td>The signs that indicate a young industry with ...</td>\n",
              "      <td>[this:\\nPick an industry where the founders of...</td>\n",
              "      <td>If the founders of the major companies in an i...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.943467</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.218941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>How do management and communication skills ben...</td>\n",
              "      <td>Management and communication skills benefit yo...</td>\n",
              "      <td>[changing the world if you can’t communicate r...</td>\n",
              "      <td>Management and communication skills benefit yo...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.612329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>How do hiring process errors affect new hire s...</td>\n",
              "      <td>I don't know.</td>\n",
              "      <td>[•\\nAnd process: how to actually run the hirin...</td>\n",
              "      <td>Hiring process errors can significantly impact...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.177981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Why focus on practical skills in college inste...</td>\n",
              "      <td>To acquire concrete skills that will be useful...</td>\n",
              "      <td>[things I would want to be told if I were ente...</td>\n",
              "      <td>Focusing on practical skills in college is imp...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.835937</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.432794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>How should emails be categorized for follow-up...</td>\n",
              "      <td>Emails should be categorized into three standi...</td>\n",
              "      <td>[keep three standing email folders: Pending, R...</td>\n",
              "      <td>Emails that require follow-up reminders go int...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.931367</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.662332</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question  \\\n",
              "0   How do the roles and responsibilities of execu...   \n",
              "1   How can internal confusion impact a startup's ...   \n",
              "2   How should founders approach market projection...   \n",
              "3   What is Rachleff's Law of Startup Success and ...   \n",
              "4   How can startups effectively hire, manage, pro...   \n",
              "5   How can combining an MBA with another degree e...   \n",
              "6   How does evolutionary behavior influence the D...   \n",
              "7   What should you do when VCs say \"no\" to fundin...   \n",
              "8   How can lack of curiosity be a danger to a sta...   \n",
              "9   How does not keeping a schedule benefit indivi...   \n",
              "10  How can targeted micromanagement help improve ...   \n",
              "11       How does email checking affect work quality?   \n",
              "12  How can a startup reduce timing risk to attrac...   \n",
              "13  What benefits does a liberal arts undergrad de...   \n",
              "14               What boosts startup funding chances?   \n",
              "15  What signs indicate a young industry with pote...   \n",
              "16  How do management and communication skills ben...   \n",
              "17  How do hiring process errors affect new hire s...   \n",
              "18  Why focus on practical skills in college inste...   \n",
              "19  How should emails be categorized for follow-up...   \n",
              "\n",
              "                                               answer  \\\n",
              "0   Executives in big companies require different ...   \n",
              "1   Internal confusion can impact a startup's stra...   \n",
              "2   Founders should approach market projections ca...   \n",
              "3   Rachleff's Law of Startup Success emphasizes t...   \n",
              "4   Startups can effectively hire, manage, promote...   \n",
              "5   Combining an MBA with another degree can be a ...   \n",
              "6   Evolutionary behavior influences the Doubt-Avo...   \n",
              "7   Meeting with more VCs after a bunch have said ...   \n",
              "8   Lack of curiosity can be a huge danger to a st...   \n",
              "9   Not keeping a schedule benefits individuals in...   \n",
              "10  Targeted micromanagement can help improve exec...   \n",
              "11  Email checking can disrupt work quality by int...   \n",
              "12  A startup can reduce timing risk by taking ste...   \n",
              "13  The benefits of a liberal arts undergrad degre...   \n",
              "14  Having the right founding team boosts startup ...   \n",
              "15  The signs that indicate a young industry with ...   \n",
              "16  Management and communication skills benefit yo...   \n",
              "17                                      I don't know.   \n",
              "18  To acquire concrete skills that will be useful...   \n",
              "19  Emails should be categorized into three standi...   \n",
              "\n",
              "                                             contexts  \\\n",
              "0   [are very Even great big company executives fr...   \n",
              "1   [ing about competitors.\\nI see two destructive...   \n",
              "2   [ularly true for startups that have not yet ac...   \n",
              "3   [Law of Startup Success:\\nT\\nThe #1 compan\\nhe...   \n",
              "4   [how to hire, manage, promote, and Xre executi...   \n",
              "5   [bly can.\\nAn MBA plus a law degree can be a g...   \n",
              "6   [Four: Doubt-Avoidance Tendency\\nThe brain of ...   \n",
              "7   [Part 2: When the VCs say \"no\"\\nThis post is a...   \n",
              "8   [the importance of hiring curious people — is ...   \n",
              "9   [By not keeping a schedule, I mean: refuse to ...   \n",
              "10  [SpeciXcally, there are times and situations w...   \n",
              "11  [address to anyone noncritical — including you...   \n",
              "12  [other startups, and also diWerentiated from a...   \n",
              "13  [liberal arts broadening your horizons.\\nWhat ...   \n",
              "14  [Xrst place. What if you have a startup for wh...   \n",
              "15  [this:\\nPick an industry where the founders of...   \n",
              "16  [changing the world if you can’t communicate r...   \n",
              "17  [•\\nAnd process: how to actually run the hirin...   \n",
              "18  [things I would want to be told if I were ente...   \n",
              "19  [keep three standing email folders: Pending, R...   \n",
              "\n",
              "                                         ground_truth  faithfulness  \\\n",
              "0   The roles and responsibilities of executives i...      1.000000   \n",
              "1   Internal confusion can impact a startup's stra...      0.000000   \n",
              "2   Founders should avoid saying they have no comp...      1.000000   \n",
              "3   Rachleff's Law of Startup Success states that ...      0.666667   \n",
              "4   Startups can effectively hire, manage, promote...      0.000000   \n",
              "5   Combining an MBA with another degree can enhan...      1.000000   \n",
              "6   Evolutionary behavior influences the Doubt-Avo...      0.500000   \n",
              "7   When VCs say 'no' to funding your startup, it ...      1.000000   \n",
              "8   Lack of curiosity can be a huge danger to a st...      1.000000   \n",
              "9   The answer to given question is not present in...      0.500000   \n",
              "10  Targeted micromanagement can help improve exec...      0.666667   \n",
              "11  Email checking affects work quality by fractur...      0.666667   \n",
              "12  To reduce timing risk and attract investors wh...      0.250000   \n",
              "13  The answer to given question is not present in...      0.000000   \n",
              "14  Having a working product that could be the fou...      1.000000   \n",
              "15  If the founders of the major companies in an i...      1.000000   \n",
              "16  Management and communication skills benefit yo...      1.000000   \n",
              "17  Hiring process errors can significantly impact...           NaN   \n",
              "18  Focusing on practical skills in college is imp...      1.000000   \n",
              "19  Emails that require follow-up reminders go int...      1.000000   \n",
              "\n",
              "    answer_relevancy  context_recall  context_precision  answer_correctness  \n",
              "0           0.957546        0.000000           0.500000                 NaN  \n",
              "1           0.998546             NaN           0.750000            0.455320  \n",
              "2           0.969808             NaN           1.000000            0.519414  \n",
              "3           0.950218        1.000000           0.583333            0.579109  \n",
              "4           0.934386        1.000000           1.000000                 NaN  \n",
              "5           0.872958             NaN           1.000000                 NaN  \n",
              "6           0.949224             NaN           1.000000                 NaN  \n",
              "7           0.937992             NaN           0.805556                 NaN  \n",
              "8           0.852250             NaN           1.000000            0.405544  \n",
              "9           1.000000        0.000000           0.000000            0.179815  \n",
              "10          1.000000        0.666667                NaN                 NaN  \n",
              "11          0.971018        1.000000           0.916667                 NaN  \n",
              "12          0.946388             NaN                NaN                 NaN  \n",
              "13          0.991984        0.000000           0.000000            0.177634  \n",
              "14          0.912488        0.000000           1.000000                 NaN  \n",
              "15          0.943467             NaN           0.916667            0.218941  \n",
              "16          1.000000        1.000000           0.833333            0.612329  \n",
              "17          0.000000        1.000000           0.333333            0.177981  \n",
              "18          0.835937        0.500000           0.500000            0.432794  \n",
              "19          0.931367        1.000000           0.805556            0.662332  "
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df = results.to_pandas()\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWfiu_pLh3JL"
      },
      "source": [
        "## Task 2: Making Adjustments to our RAG Pipeline\n",
        "\n",
        "Now that we have established a baseline - we can see how any changes impact our pipeline's performance!\n",
        "\n",
        "Let's modify our retriever and see how that impacts our Ragas metrics!\n",
        "\n",
        "> NOTE: MultiQueryRetriever is expanded on [here](https://python.langchain.com/docs/modules/data_connection/retrievers/MultiQueryRetriever) but for now, the implementation is not important to our lesson!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "nKIuM336isBL"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import MultiQueryRetriever\n",
        "\n",
        "advanced_retriever = MultiQueryRetriever.from_llm(retriever=retriever, llm=primary_qa_llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82rcj3L-i_c8"
      },
      "source": [
        "We'll also re-create our RAG pipeline using the abstractions that come packaged with LangChain v0.1.0!\n",
        "\n",
        "First, let's create a chain to \"stuff\" our documents into our context!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "EfdCgTw7jC4i"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "document_chain = create_stuff_documents_chain(primary_qa_llm, retrieval_qa_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozYl5WdPnvLu"
      },
      "source": [
        "Next, we'll create the retrieval chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "9AK7wHVnn0U3"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "\n",
        "retrieval_chain = create_retrieval_chain(advanced_retriever, document_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "cmKORMfMoCjL"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8353' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=TimeoutError()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 316, in __step_run_and_handle_result\n",
            "    result = coro.throw(exc)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8354' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=TimeoutError()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1589, in _request\n",
            "    response.raise_for_status()\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_models.py\", line 761, in raise_for_status\n",
            "    raise HTTPStatusError(message, request=request, response=self)\n",
            "httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'\n",
            "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_precision.py\", line 161, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 58, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 110, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 78, in inner\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/__init__.py\", line 390, in <lambda>\n",
            "    self._add_action_func(lambda rs: rs.outcome.result())\n",
            "                                     ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 61, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 170, in agenerate_text\n",
            "    return await self.langchain_llm.agenerate_prompt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 723, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 649, in agenerate\n",
            "    results = await asyncio.gather(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 316, in __step_run_and_handle_result\n",
            "    result = coro.throw(exc)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 868, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 674, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1514, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1595, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1641, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1595, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1639, in _retry_request\n",
            "    await anyio.sleep(timeout)\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/anyio/_core/_eventloop.py\", line 86, in sleep\n",
            "    return await get_async_backend().sleep(delay)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 2045, in sleep\n",
            "    await sleep(delay)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 316, in __step_run_and_handle_result\n",
            "    result = coro.throw(exc)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8356' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=TimeoutError()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 316, in __step_run_and_handle_result\n",
            "    result = coro.throw(exc)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8357' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=TimeoutError()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 316, in __step_run_and_handle_result\n",
            "    result = coro.throw(exc)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8361' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=TimeoutError()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 316, in __step_run_and_handle_result\n",
            "    result = coro.throw(exc)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8365' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=KeyError('idle_for')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 58, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 110, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 78, in inner\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/__init__.py\", line 420, in next_action\n",
            "    self.statistics[\"idle_for\"] += sleep\n",
            "    ~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "KeyError: 'idle_for'\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8366' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=TimeoutError()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 316, in __step_run_and_handle_result\n",
            "    result = coro.throw(exc)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8373' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AttributeError(\"'NoneType' object has no attribute 'generate'\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_precision.py\", line 161, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "                    ^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'generate'\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8381' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=KeyError('idle_for')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 58, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 110, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 78, in inner\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/__init__.py\", line 420, in next_action\n",
            "    self.statistics[\"idle_for\"] += sleep\n",
            "    ~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "KeyError: 'idle_for'\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8382' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('AnswerSimilarity must be set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 268, in _ascore\n",
            "    assert self.answer_similarity is not None, \"AnswerSimilarity must be set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: AnswerSimilarity must be set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8385' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=KeyError('idle_for')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 58, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 110, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 78, in inner\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/__init__.py\", line 420, in next_action\n",
            "    self.statistics[\"idle_for\"] += sleep\n",
            "    ~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "KeyError: 'idle_for'\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8390' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AttributeError(\"'NoneType' object has no attribute 'generate'\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                                 ^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'generate'\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8392' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('llm must be set to compute score')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_faithfulness.py\", line 265, in _ascore\n",
            "    p_value = self._create_nli_prompt(row, statements)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_faithfulness.py\", line 200, in _create_nli_prompt\n",
            "    assert self.llm is not None, \"llm must be set to compute score\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: llm must be set to compute score\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8393' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_faithfulness.py\", line 245, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8394' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('set LLM before use')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 167, in _ascore\n",
            "    assert self.llm is not None, \"set LLM before use\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: set LLM before use\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8395' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM must be set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 215, in _ascore\n",
            "    assert self.llm is not None, \"LLM must be set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM must be set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8396' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_precision.py\", line 156, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8397' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_faithfulness.py\", line 245, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8398' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_relevance.py\", line 149, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8399' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM must be set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 215, in _ascore\n",
            "    assert self.llm is not None, \"LLM must be set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM must be set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8400' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_relevance.py\", line 149, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8401' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_faithfulness.py\", line 245, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8402' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_relevance.py\", line 149, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8403' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('set LLM before use')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 167, in _ascore\n",
            "    assert self.llm is not None, \"set LLM before use\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: set LLM before use\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8404' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('set LLM before use')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 167, in _ascore\n",
            "    assert self.llm is not None, \"set LLM before use\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: set LLM before use\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8405' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM must be set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 215, in _ascore\n",
            "    assert self.llm is not None, \"LLM must be set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM must be set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8406' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('set LLM before use')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 167, in _ascore\n",
            "    assert self.llm is not None, \"set LLM before use\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: set LLM before use\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8407' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_faithfulness.py\", line 245, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8408' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_faithfulness.py\", line 245, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8409' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM must be set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 215, in _ascore\n",
            "    assert self.llm is not None, \"LLM must be set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM must be set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8410' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_precision.py\", line 156, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8411' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_precision.py\", line 156, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8412' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM must be set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 215, in _ascore\n",
            "    assert self.llm is not None, \"LLM must be set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM must be set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8413' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_faithfulness.py\", line 245, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8414' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_faithfulness.py\", line 245, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8415' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('set LLM before use')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 167, in _ascore\n",
            "    assert self.llm is not None, \"set LLM before use\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: set LLM before use\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-8416' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM must be set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 215, in _ascore\n",
            "    assert self.llm is not None, \"LLM must be set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM must be set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9624' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_precision.py\", line 156, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9574' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=TimeoutError()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 316, in __step_run_and_handle_result\n",
            "    result = coro.throw(exc)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9575' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=TimeoutError()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 316, in __step_run_and_handle_result\n",
            "    result = coro.throw(exc)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9579' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=TimeoutError()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_precision.py\", line 161, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 316, in __step_run_and_handle_result\n",
            "    result = coro.throw(exc)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9584' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=TimeoutError()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 58, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 110, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 78, in inner\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/__init__.py\", line 390, in <lambda>\n",
            "    self._add_action_func(lambda rs: rs.outcome.result())\n",
            "                                     ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 61, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 170, in agenerate_text\n",
            "    return await self.langchain_llm.agenerate_prompt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 723, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 649, in agenerate\n",
            "    results = await asyncio.gather(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 868, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 674, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1514, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1548, in _request\n",
            "    response = await self._client.send(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1661, in send\n",
            "    response = await self._send_handling_auth(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1689, in _send_handling_auth\n",
            "    response = await self._send_handling_redirects(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1726, in _send_handling_redirects\n",
            "    response = await self._send_single_request(request)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1763, in _send_single_request\n",
            "    response = await transport.handle_async_request(request)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 373, in handle_async_request\n",
            "    resp = await self._pool.handle_async_request(req)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 216, in handle_async_request\n",
            "    raise exc from None\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 196, in handle_async_request\n",
            "    response = await connection.handle_async_request(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/connection.py\", line 101, in handle_async_request\n",
            "    return await self._connection.handle_async_request(request)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 143, in handle_async_request\n",
            "    raise exc\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 113, in handle_async_request\n",
            "    ) = await self._receive_response_headers(**kwargs)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 186, in _receive_response_headers\n",
            "    event = await self._receive_event(timeout=timeout)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 224, in _receive_event\n",
            "    data = await self._network_stream.read(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
            "    return await self._stream.receive(max_bytes=max_bytes)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/anyio/streams/tls.py\", line 205, in receive\n",
            "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/anyio/streams/tls.py\", line 147, in _call_sslobject_method\n",
            "    data = await self.transport_stream.receive()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 1133, in receive\n",
            "    await self._protocol.read_event.wait()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
            "    await fut\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 316, in __step_run_and_handle_result\n",
            "    result = coro.throw(exc)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9586' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=TimeoutError()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 58, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 110, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 78, in inner\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/__init__.py\", line 390, in <lambda>\n",
            "    self._add_action_func(lambda rs: rs.outcome.result())\n",
            "                                     ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 61, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 170, in agenerate_text\n",
            "    return await self.langchain_llm.agenerate_prompt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 723, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 649, in agenerate\n",
            "    results = await asyncio.gather(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 868, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 674, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1514, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1548, in _request\n",
            "    response = await self._client.send(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1661, in send\n",
            "    response = await self._send_handling_auth(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1689, in _send_handling_auth\n",
            "    response = await self._send_handling_redirects(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1726, in _send_handling_redirects\n",
            "    response = await self._send_single_request(request)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1763, in _send_single_request\n",
            "    response = await transport.handle_async_request(request)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 373, in handle_async_request\n",
            "    resp = await self._pool.handle_async_request(req)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 216, in handle_async_request\n",
            "    raise exc from None\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 196, in handle_async_request\n",
            "    response = await connection.handle_async_request(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/connection.py\", line 101, in handle_async_request\n",
            "    return await self._connection.handle_async_request(request)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 143, in handle_async_request\n",
            "    raise exc\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 113, in handle_async_request\n",
            "    ) = await self._receive_response_headers(**kwargs)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 186, in _receive_response_headers\n",
            "    event = await self._receive_event(timeout=timeout)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 224, in _receive_event\n",
            "    data = await self._network_stream.read(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
            "    return await self._stream.receive(max_bytes=max_bytes)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/anyio/streams/tls.py\", line 205, in receive\n",
            "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/anyio/streams/tls.py\", line 147, in _call_sslobject_method\n",
            "    data = await self.transport_stream.receive()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 1133, in receive\n",
            "    await self._protocol.read_event.wait()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
            "    await fut\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 316, in __step_run_and_handle_result\n",
            "    result = coro.throw(exc)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9589' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=TimeoutError()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 316, in __step_run_and_handle_result\n",
            "    result = coro.throw(exc)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9599' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('AnswerSimilarity must be set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 268, in _ascore\n",
            "    assert self.answer_similarity is not None, \"AnswerSimilarity must be set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: AnswerSimilarity must be set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9603' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=KeyError('idle_for')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 58, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 110, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 78, in inner\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/__init__.py\", line 420, in next_action\n",
            "    self.statistics[\"idle_for\"] += sleep\n",
            "    ~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "KeyError: 'idle_for'\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9608' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('AnswerSimilarity must be set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 268, in _ascore\n",
            "    assert self.answer_similarity is not None, \"AnswerSimilarity must be set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: AnswerSimilarity must be set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9610' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=KeyError('idle_for')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 58, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 110, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 78, in inner\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/__init__.py\", line 420, in next_action\n",
            "    self.statistics[\"idle_for\"] += sleep\n",
            "    ~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "KeyError: 'idle_for'\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9611' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AttributeError(\"'NoneType' object has no attribute 'generate'\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_precision.py\", line 161, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "                    ^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'generate'\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9612' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AttributeError(\"'NoneType' object has no attribute 'generate'\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_precision.py\", line 161, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "                    ^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'generate'\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9613' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AttributeError(\"'NoneType' object has no attribute 'generate'\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                                 ^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'generate'\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9615' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=KeyError('idle_for')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 58, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 110, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 78, in inner\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/__init__.py\", line 420, in next_action\n",
            "    self.statistics[\"idle_for\"] += sleep\n",
            "    ~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "KeyError: 'idle_for'\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9616' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('llm must be set to compute score')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_faithfulness.py\", line 265, in _ascore\n",
            "    p_value = self._create_nli_prompt(row, statements)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_faithfulness.py\", line 200, in _create_nli_prompt\n",
            "    assert self.llm is not None, \"llm must be set to compute score\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: llm must be set to compute score\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9617' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_relevance.py\", line 149, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9618' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_faithfulness.py\", line 245, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9619' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM must be set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 215, in _ascore\n",
            "    assert self.llm is not None, \"LLM must be set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM must be set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9620' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM must be set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 215, in _ascore\n",
            "    assert self.llm is not None, \"LLM must be set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM must be set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9621' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_faithfulness.py\", line 245, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9622' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_faithfulness.py\", line 245, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9623' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_precision.py\", line 156, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9625' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_precision.py\", line 156, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9626' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('set LLM before use')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 167, in _ascore\n",
            "    assert self.llm is not None, \"set LLM before use\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: set LLM before use\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9627' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('set LLM before use')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 167, in _ascore\n",
            "    assert self.llm is not None, \"set LLM before use\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: set LLM before use\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9628' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('set LLM before use')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 167, in _ascore\n",
            "    assert self.llm is not None, \"set LLM before use\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: set LLM before use\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9629' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_relevance.py\", line 149, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9630' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM must be set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 215, in _ascore\n",
            "    assert self.llm is not None, \"LLM must be set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM must be set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9631' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_relevance.py\", line 149, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9632' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_precision.py\", line 156, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9633' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_relevance.py\", line 149, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9634' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_faithfulness.py\", line 245, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9635' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('set LLM before use')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 167, in _ascore\n",
            "    assert self.llm is not None, \"set LLM before use\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: set LLM before use\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9636' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('set LLM before use')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 167, in _ascore\n",
            "    assert self.llm is not None, \"set LLM before use\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: set LLM before use\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9637' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_relevance.py\", line 149, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9638' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_faithfulness.py\", line 245, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9639' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_precision.py\", line 156, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9640' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_precision.py\", line 156, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9641' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('set LLM before use')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 167, in _ascore\n",
            "    assert self.llm is not None, \"set LLM before use\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: set LLM before use\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9642' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_relevance.py\", line 149, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9643' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_faithfulness.py\", line 245, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9644' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM must be set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 215, in _ascore\n",
            "    assert self.llm is not None, \"LLM must be set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM must be set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9645' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('set LLM before use')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 167, in _ascore\n",
            "    assert self.llm is not None, \"set LLM before use\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: set LLM before use\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9646' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_relevance.py\", line 149, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9647' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_precision.py\", line 156, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9648' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM must be set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 215, in _ascore\n",
            "    assert self.llm is not None, \"LLM must be set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM must be set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9649' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM must be set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 215, in _ascore\n",
            "    assert self.llm is not None, \"LLM must be set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM must be set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9650' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_relevance.py\", line 149, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9651' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('set LLM before use')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 167, in _ascore\n",
            "    assert self.llm is not None, \"set LLM before use\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: set LLM before use\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9652' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_relevance.py\", line 149, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9653' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_relevance.py\", line 149, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9654' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM is not set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_faithfulness.py\", line 245, in _ascore\n",
            "    assert self.llm is not None, \"LLM is not set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM is not set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9655' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=AssertionError('LLM must be set')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 215, in _ascore\n",
            "    assert self.llm is not None, \"LLM must be set\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: LLM must be set\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-9563' coro=<as_completed.<locals>.sema_coro() done, defined at /opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py:35> exception=TimeoutError()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 316, in __step_run_and_handle_result\n",
            "    result = coro.throw(exc)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 37, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n"
          ]
        }
      ],
      "source": [
        "response = retrieval_chain.invoke({\"input\": \"Who is Taylor Swift fueding with?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICMsUWbWoOpf",
        "outputId": "1c2a8c65-0da8-44ef-d6e4-79dcca738777"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I'm sorry, but I cannot provide an answer to your question based on the context provided.\n"
          ]
        }
      ],
      "source": [
        "print(response[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "5s8ZGasYoVi6"
      },
      "outputs": [],
      "source": [
        "response = retrieval_chain.invoke({\"input\": \"Why are they fueding?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADNCdW4hoYT8",
        "outputId": "40860a4e-75fb-486e-b1e6-34a7eb2c5295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The feud mentioned in the context seems to be between two groups, with one group having raised a lot of money while the other did not. The reason for the feud is not explicitly stated in the provided text.\n"
          ]
        }
      ],
      "source": [
        "print(response[\"answer\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxkU0HdpoaiE"
      },
      "source": [
        "Well, just from those responses this chain *feels* better - but lets see how it performs on our eval!\n",
        "\n",
        "Let's do the same process we did before to collect our pipeline's contexts and answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "kO8cWxn2oinT"
      },
      "outputs": [],
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = retrieval_chain.invoke({\"input\" : question})\n",
        "  answers.append(response[\"answer\"])\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgagfhPUtM2j"
      },
      "source": [
        "Now we can convert this into a dataset, just like we did before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "5FcllGeSovP8"
      },
      "outputs": [],
      "source": [
        "response_dataset_advanced_retrieval = Dataset.from_dict({\n",
        "    \"question\" : test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : test_groundtruths\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dELYabwktR2C"
      },
      "source": [
        "Let's evaluate on the same metrics we did for the first pipeline and see how it does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "831b4dab6ff94d239d2824d390e01308",
            "4cefefc6cf714a68924e1b8d5e59aba9",
            "fd7f5542a22d44388dda12ca19443a1f",
            "93bf9b194c04460abffa192c19bcf67b",
            "83985f58744a46cfbd001ce5957f3e4a",
            "5c2b92989d7448e9bf65306c4f2f7d93",
            "a34b3906cd514234a115c7bf6757ca9d",
            "a03fefb9fa5a40ff947dc4ccd3c80318",
            "40343486e3ea4e5fae55b5a528f139d8",
            "cee2268aa21643e6ad77117c67ec1600",
            "c79f28da88f44d69aa87905c089df333"
          ]
        },
        "id": "d7uHseWJo2TU",
        "outputId": "8facfba9-467a-4129-b381-ddbd0a952f28"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "251e56e340624a93bf37a0394fa38c88",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_precision.py\", line 161, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_precision.py\", line 161, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_precision.py\", line 161, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 58, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 110, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 78, in inner\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/__init__.py\", line 390, in <lambda>\n",
            "    self._add_action_func(lambda rs: rs.outcome.result())\n",
            "                                     ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 61, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 170, in agenerate_text\n",
            "    return await self.langchain_llm.agenerate_prompt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 723, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 649, in agenerate\n",
            "    results = await asyncio.gather(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 868, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 674, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1514, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1595, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1641, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1548, in _request\n",
            "    response = await self._client.send(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1661, in send\n",
            "    response = await self._send_handling_auth(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1689, in _send_handling_auth\n",
            "    response = await self._send_handling_redirects(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1726, in _send_handling_redirects\n",
            "    response = await self._send_single_request(request)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1763, in _send_single_request\n",
            "    response = await transport.handle_async_request(request)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 373, in handle_async_request\n",
            "    resp = await self._pool.handle_async_request(req)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 216, in handle_async_request\n",
            "    raise exc from None\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 196, in handle_async_request\n",
            "    response = await connection.handle_async_request(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/connection.py\", line 101, in handle_async_request\n",
            "    return await self._connection.handle_async_request(request)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 143, in handle_async_request\n",
            "    raise exc\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 113, in handle_async_request\n",
            "    ) = await self._receive_response_headers(**kwargs)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 186, in _receive_response_headers\n",
            "    event = await self._receive_event(timeout=timeout)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 224, in _receive_event\n",
            "    data = await self._network_stream.read(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
            "    return await self._stream.receive(max_bytes=max_bytes)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/anyio/streams/tls.py\", line 205, in receive\n",
            "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/anyio/streams/tls.py\", line 147, in _call_sslobject_method\n",
            "    data = await self.transport_stream.receive()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 1133, in receive\n",
            "    await self._protocol.read_event.wait()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
            "    await fut\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 58, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 110, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 78, in inner\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/__init__.py\", line 390, in <lambda>\n",
            "    self._add_action_func(lambda rs: rs.outcome.result())\n",
            "                                     ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 61, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 170, in agenerate_text\n",
            "    return await self.langchain_llm.agenerate_prompt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 723, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 649, in agenerate\n",
            "    results = await asyncio.gather(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 868, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 674, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1514, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1595, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1641, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py\", line 1548, in _request\n",
            "    response = await self._client.send(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1661, in send\n",
            "    response = await self._send_handling_auth(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1689, in _send_handling_auth\n",
            "    response = await self._send_handling_redirects(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1726, in _send_handling_redirects\n",
            "    response = await self._send_single_request(request)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py\", line 1763, in _send_single_request\n",
            "    response = await transport.handle_async_request(request)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpx/_transports/default.py\", line 373, in handle_async_request\n",
            "    resp = await self._pool.handle_async_request(req)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 216, in handle_async_request\n",
            "    raise exc from None\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 196, in handle_async_request\n",
            "    response = await connection.handle_async_request(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/connection.py\", line 101, in handle_async_request\n",
            "    return await self._connection.handle_async_request(request)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 143, in handle_async_request\n",
            "    raise exc\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 113, in handle_async_request\n",
            "    ) = await self._receive_response_headers(**kwargs)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 186, in _receive_response_headers\n",
            "    event = await self._receive_event(timeout=timeout)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 224, in _receive_event\n",
            "    data = await self._network_stream.read(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
            "    return await self._stream.receive(max_bytes=max_bytes)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/anyio/streams/tls.py\", line 205, in receive\n",
            "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/anyio/streams/tls.py\", line 147, in _call_sslobject_method\n",
            "    data = await self.transport_stream.receive()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 1133, in receive\n",
            "    await self._protocol.read_event.wait()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
            "    await fut\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_precision.py\", line 161, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_precision.py\", line 161, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_precision.py\", line 161, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 250, in _ascore\n",
            "    is_statement_present = await self.llm.generate(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n",
            "Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py\", line 169, in _ascore\n",
            "    results = await self.llm.generate(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py\", line 93, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 142, in async_wrapped\n",
            "    return await fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/tenacity/_asyncio.py\", line 68, in __call__\n",
            "    await self.sleep(do)\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 665, in sleep\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
            "    future.result()\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/futures.py\", line 198, in result\n",
            "    raise exc\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/executor.py\", line 104, in wrapped_callable_async\n",
            "    result = await callable(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 134, in ascore\n",
            "    raise e\n",
            "  File \"/opt/miniconda3/lib/python3.12/site-packages/ragas/metrics/base.py\", line 127, in ascore\n",
            "    score = await asyncio.wait_for(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/tasks.py\", line 519, in wait_for\n",
            "    async with timeouts.timeout(timeout):\n",
            "  File \"/opt/miniconda3/lib/python3.12/asyncio/timeouts.py\", line 115, in __aexit__\n",
            "    raise TimeoutError from exc_val\n",
            "TimeoutError\n"
          ]
        }
      ],
      "source": [
        "advanced_retrieval_results = evaluate(response_dataset_advanced_retrieval, metrics, raise_exceptions=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JsFd0uDd2n5E",
        "outputId": "0922ab45-c16a-48c4-c9c2-3647ff130391"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>answer_correctness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How do the roles and responsibilities of execu...</td>\n",
              "      <td>The executive skill sets required for a big co...</td>\n",
              "      <td>[are very Even great big company executives fr...</td>\n",
              "      <td>The roles and responsibilities of executives i...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.959817</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How can internal confusion impact a startup's ...</td>\n",
              "      <td>Internal confusion within a startup can impact...</td>\n",
              "      <td>[ing about competitors.\\nI see two destructive...</td>\n",
              "      <td>Internal confusion can impact a startup's stra...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.995979</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.426376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How should founders approach market projection...</td>\n",
              "      <td>Founders should approach market projections in...</td>\n",
              "      <td>[founding team with a business person, you hav...</td>\n",
              "      <td>Founders should avoid saying they have no comp...</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.969808</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is Rachleff's Law of Startup Success and ...</td>\n",
              "      <td>Rachleff's Law of Startup Success emphasizes t...</td>\n",
              "      <td>[Law of Startup Success:\\nT\\nThe #1 compan\\nhe...</td>\n",
              "      <td>Rachleff's Law of Startup Success states that ...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.950218</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How can startups effectively hire, manage, pro...</td>\n",
              "      <td>Startups can effectively hire, manage, promote...</td>\n",
              "      <td>[how to hire, manage, promote, and Xre executi...</td>\n",
              "      <td>Startups can effectively hire, manage, promote...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How can combining an MBA with another degree e...</td>\n",
              "      <td>Combining an MBA with another degree can enhan...</td>\n",
              "      <td>[bly can.\\nAn MBA plus a law degree can be a g...</td>\n",
              "      <td>Combining an MBA with another degree can enhan...</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How does evolutionary behavior influence the D...</td>\n",
              "      <td>Evolutionary behavior may influence the Doubt-...</td>\n",
              "      <td>[Tendency, what usually triggers Doubt-Avoidan...</td>\n",
              "      <td>Evolutionary behavior influences the Doubt-Avo...</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.916201</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.721812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What should you do when VCs say \"no\" to fundin...</td>\n",
              "      <td>When VCs say \"no\" to funding your startup, it ...</td>\n",
              "      <td>[Xrst place. What if you have a startup for wh...</td>\n",
              "      <td>When VCs say 'no' to funding your startup, it ...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.999141</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.810000</td>\n",
              "      <td>0.796941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How can lack of curiosity be a danger to a sta...</td>\n",
              "      <td>Lack of curiosity can be a danger to a startup...</td>\n",
              "      <td>[the importance of hiring curious people — is ...</td>\n",
              "      <td>Lack of curiosity can be a huge danger to a st...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.962270</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.560285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How does not keeping a schedule benefit indivi...</td>\n",
              "      <td>Not keeping a schedule can benefit individuals...</td>\n",
              "      <td>[sibilities where they can’t do that. Or maybe...</td>\n",
              "      <td>The answer to given question is not present in...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.993320</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How can targeted micromanagement help improve ...</td>\n",
              "      <td>Targeted micromanagement can help improve exec...</td>\n",
              "      <td>[the practice of micromanagement on that basis...</td>\n",
              "      <td>Targeted micromanagement can help improve exec...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.638889</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>How does email checking affect work quality?</td>\n",
              "      <td>Checking email frequently can disrupt your wor...</td>\n",
              "      <td>[address to anyone noncritical — including you...</td>\n",
              "      <td>Email checking affects work quality by fractur...</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.899443</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.729807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>How can a startup reduce timing risk to attrac...</td>\n",
              "      <td>A startup can reduce timing risk by conducting...</td>\n",
              "      <td>[other startups, and also diWerentiated from a...</td>\n",
              "      <td>To reduce timing risk and attract investors wh...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.931214</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.926667</td>\n",
              "      <td>0.638617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What benefits does a liberal arts undergrad de...</td>\n",
              "      <td>A liberal arts undergrad degree combined with ...</td>\n",
              "      <td>[liberal arts broadening your horizons.\\nWhat ...</td>\n",
              "      <td>The answer to given question is not present in...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.821177</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>What boosts startup funding chances?</td>\n",
              "      <td>To boost startup funding chances, a startup ca...</td>\n",
              "      <td>[How much funding for a startup is too little?...</td>\n",
              "      <td>Having a working product that could be the fou...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.954449</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>What signs indicate a young industry with pote...</td>\n",
              "      <td>Signs that indicate a young industry with pote...</td>\n",
              "      <td>[this:\\nPick an industry where the founders of...</td>\n",
              "      <td>If the founders of the major companies in an i...</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.993607</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.926667</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>How do management and communication skills ben...</td>\n",
              "      <td>Management and communication skills are highly...</td>\n",
              "      <td>[changing the world if you can’t communicate r...</td>\n",
              "      <td>Management and communication skills benefit yo...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.860870</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>How do hiring process errors affect new hire s...</td>\n",
              "      <td>Hiring process errors can significantly impact...</td>\n",
              "      <td>[•\\nAnd process: how to actually run the hirin...</td>\n",
              "      <td>Hiring process errors can significantly impact...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.940713</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.454254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Why focus on practical skills in college inste...</td>\n",
              "      <td>Focusing on practical skills in college can be...</td>\n",
              "      <td>[things I would want to be told if I were ente...</td>\n",
              "      <td>Focusing on practical skills in college is imp...</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.835937</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.679167</td>\n",
              "      <td>0.584377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>How should emails be categorized for follow-up...</td>\n",
              "      <td>Emails that require follow-up reminders can be...</td>\n",
              "      <td>[is nearly endless.\\nDo email exactly twice a ...</td>\n",
              "      <td>Emails that require follow-up reminders go int...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.902006</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.679167</td>\n",
              "      <td>0.448890</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question  \\\n",
              "0   How do the roles and responsibilities of execu...   \n",
              "1   How can internal confusion impact a startup's ...   \n",
              "2   How should founders approach market projection...   \n",
              "3   What is Rachleff's Law of Startup Success and ...   \n",
              "4   How can startups effectively hire, manage, pro...   \n",
              "5   How can combining an MBA with another degree e...   \n",
              "6   How does evolutionary behavior influence the D...   \n",
              "7   What should you do when VCs say \"no\" to fundin...   \n",
              "8   How can lack of curiosity be a danger to a sta...   \n",
              "9   How does not keeping a schedule benefit indivi...   \n",
              "10  How can targeted micromanagement help improve ...   \n",
              "11       How does email checking affect work quality?   \n",
              "12  How can a startup reduce timing risk to attrac...   \n",
              "13  What benefits does a liberal arts undergrad de...   \n",
              "14               What boosts startup funding chances?   \n",
              "15  What signs indicate a young industry with pote...   \n",
              "16  How do management and communication skills ben...   \n",
              "17  How do hiring process errors affect new hire s...   \n",
              "18  Why focus on practical skills in college inste...   \n",
              "19  How should emails be categorized for follow-up...   \n",
              "\n",
              "                                               answer  \\\n",
              "0   The executive skill sets required for a big co...   \n",
              "1   Internal confusion within a startup can impact...   \n",
              "2   Founders should approach market projections in...   \n",
              "3   Rachleff's Law of Startup Success emphasizes t...   \n",
              "4   Startups can effectively hire, manage, promote...   \n",
              "5   Combining an MBA with another degree can enhan...   \n",
              "6   Evolutionary behavior may influence the Doubt-...   \n",
              "7   When VCs say \"no\" to funding your startup, it ...   \n",
              "8   Lack of curiosity can be a danger to a startup...   \n",
              "9   Not keeping a schedule can benefit individuals...   \n",
              "10  Targeted micromanagement can help improve exec...   \n",
              "11  Checking email frequently can disrupt your wor...   \n",
              "12  A startup can reduce timing risk by conducting...   \n",
              "13  A liberal arts undergrad degree combined with ...   \n",
              "14  To boost startup funding chances, a startup ca...   \n",
              "15  Signs that indicate a young industry with pote...   \n",
              "16  Management and communication skills are highly...   \n",
              "17  Hiring process errors can significantly impact...   \n",
              "18  Focusing on practical skills in college can be...   \n",
              "19  Emails that require follow-up reminders can be...   \n",
              "\n",
              "                                             contexts  \\\n",
              "0   [are very Even great big company executives fr...   \n",
              "1   [ing about competitors.\\nI see two destructive...   \n",
              "2   [founding team with a business person, you hav...   \n",
              "3   [Law of Startup Success:\\nT\\nThe #1 compan\\nhe...   \n",
              "4   [how to hire, manage, promote, and Xre executi...   \n",
              "5   [bly can.\\nAn MBA plus a law degree can be a g...   \n",
              "6   [Tendency, what usually triggers Doubt-Avoidan...   \n",
              "7   [Xrst place. What if you have a startup for wh...   \n",
              "8   [the importance of hiring curious people — is ...   \n",
              "9   [sibilities where they can’t do that. Or maybe...   \n",
              "10  [the practice of micromanagement on that basis...   \n",
              "11  [address to anyone noncritical — including you...   \n",
              "12  [other startups, and also diWerentiated from a...   \n",
              "13  [liberal arts broadening your horizons.\\nWhat ...   \n",
              "14  [How much funding for a startup is too little?...   \n",
              "15  [this:\\nPick an industry where the founders of...   \n",
              "16  [changing the world if you can’t communicate r...   \n",
              "17  [•\\nAnd process: how to actually run the hirin...   \n",
              "18  [things I would want to be told if I were ente...   \n",
              "19  [is nearly endless.\\nDo email exactly twice a ...   \n",
              "\n",
              "                                         ground_truth  faithfulness  \\\n",
              "0   The roles and responsibilities of executives i...      1.000000   \n",
              "1   Internal confusion can impact a startup's stra...      0.000000   \n",
              "2   Founders should avoid saying they have no comp...      0.714286   \n",
              "3   Rachleff's Law of Startup Success states that ...      1.000000   \n",
              "4   Startups can effectively hire, manage, promote...      1.000000   \n",
              "5   Combining an MBA with another degree can enhan...      0.166667   \n",
              "6   Evolutionary behavior influences the Doubt-Avo...      0.250000   \n",
              "7   When VCs say 'no' to funding your startup, it ...      1.000000   \n",
              "8   Lack of curiosity can be a huge danger to a st...      1.000000   \n",
              "9   The answer to given question is not present in...      0.500000   \n",
              "10  Targeted micromanagement can help improve exec...      0.666667   \n",
              "11  Email checking affects work quality by fractur...      0.333333   \n",
              "12  To reduce timing risk and attract investors wh...      0.500000   \n",
              "13  The answer to given question is not present in...      0.666667   \n",
              "14  Having a working product that could be the fou...      0.500000   \n",
              "15  If the founders of the major companies in an i...      0.333333   \n",
              "16  Management and communication skills benefit yo...      1.000000   \n",
              "17  Hiring process errors can significantly impact...      1.000000   \n",
              "18  Focusing on practical skills in college is imp...      0.833333   \n",
              "19  Emails that require follow-up reminders go int...      0.000000   \n",
              "\n",
              "    answer_relevancy  context_recall  context_precision  answer_correctness  \n",
              "0           0.959817        0.000000           0.250000                 NaN  \n",
              "1           0.995979        0.000000                NaN            0.426376  \n",
              "2           0.969808             NaN           1.000000                 NaN  \n",
              "3           0.950218        1.000000           0.416667                 NaN  \n",
              "4           1.000000             NaN                NaN                 NaN  \n",
              "5           1.000000        1.000000           0.833333                 NaN  \n",
              "6           0.916201             NaN                NaN            0.721812  \n",
              "7           0.999141        1.000000           0.810000            0.796941  \n",
              "8           0.962270             NaN                NaN            0.560285  \n",
              "9           0.993320             NaN           0.000000            0.178363  \n",
              "10          1.000000        0.666667           0.638889                 NaN  \n",
              "11          0.899443        1.000000           1.000000            0.729807  \n",
              "12          0.931214             NaN           0.926667            0.638617  \n",
              "13          0.821177        0.000000           0.000000                 NaN  \n",
              "14          0.954449             NaN           0.916667                 NaN  \n",
              "15          0.993607             NaN           0.926667                 NaN  \n",
              "16          0.860870        1.000000                NaN                 NaN  \n",
              "17          0.940713             NaN                NaN            0.454254  \n",
              "18          0.835937        0.500000           0.679167            0.584377  \n",
              "19          0.902006        1.000000           0.679167            0.448890  "
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "advanced_retrieval_results_df = advanced_retrieval_results.to_pandas()\n",
        "advanced_retrieval_results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0hzqq5VtZ2a"
      },
      "source": [
        "## Task 3: Evaluating our Adjusted Pipeline Against Our Baseline\n",
        "\n",
        "Now we can compare our results and see what directional changes occured!\n",
        "\n",
        "Let's refresh with our initial metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WWGRaF5qx3V",
        "outputId": "7924b9a5-1bfc-4d26-f1f7-75e10fb64857"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.6255, 'answer_relevancy': 0.8526, 'context_recall': 0.6500, 'context_precision': 0.7583, 'answer_correctness': 0.5520}"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFv_yAeotmFs"
      },
      "source": [
        "And see how our advanced retrieval modified our chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpV11dxJo7xa",
        "outputId": "2ce6e4b7-f037-4fd4-ca0c-1d47ff5dc522"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.7120, 'answer_relevancy': 0.9455, 'context_recall': 0.7417, 'context_precision': 0.7112, 'answer_correctness': 0.5529}"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "advanced_retrieval_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "62NYn3iAvTjM",
        "outputId": "732eec56-d4ef-4403-cc90-62d0c81c37cf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_merged\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Metric\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"answer_relevancy\",\n          \"answer_correctness\",\n          \"context_recall\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Baseline\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11820882731030606,\n        \"min\": 0.5519819867147012,\n        \"max\": 0.8526045555079783,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8526045555079783,\n          0.5519819867147012,\n          0.65\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MultiQueryRetriever with Document Stuffing\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14015826154350428,\n        \"min\": 0.552913718421707,\n        \"max\": 0.9454990446409471,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9454990446409471,\n          0.552913718421707,\n          0.7416666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Delta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06447889826571732,\n        \"min\": -0.047148809514070855,\n        \"max\": 0.09289448913296883,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.09289448913296883,\n          0.0009317317070057785,\n          0.09166666666666656\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_merged"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-dd80dcd2-ef19-470f-ad76-8e3669d45c3f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Baseline</th>\n",
              "      <th>MultiQueryRetriever with Document Stuffing</th>\n",
              "      <th>Delta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>faithfulness</td>\n",
              "      <td>0.625490</td>\n",
              "      <td>0.712024</td>\n",
              "      <td>0.086534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>answer_relevancy</td>\n",
              "      <td>0.852605</td>\n",
              "      <td>0.945499</td>\n",
              "      <td>0.092894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.741667</td>\n",
              "      <td>0.091667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.758333</td>\n",
              "      <td>0.711185</td>\n",
              "      <td>-0.047149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.551982</td>\n",
              "      <td>0.552914</td>\n",
              "      <td>0.000932</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd80dcd2-ef19-470f-ad76-8e3669d45c3f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dd80dcd2-ef19-470f-ad76-8e3669d45c3f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dd80dcd2-ef19-470f-ad76-8e3669d45c3f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2136134a-3a40-45d2-bca8-7580db7dd2b7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2136134a-3a40-45d2-bca8-7580db7dd2b7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2136134a-3a40-45d2-bca8-7580db7dd2b7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_27670a9f-c0e8-496d-93fc-e31fe1e3396c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_merged')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_27670a9f-c0e8-496d-93fc-e31fe1e3396c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_merged');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "               Metric  Baseline  MultiQueryRetriever with Document Stuffing  \\\n",
              "0        faithfulness  0.625490                                    0.712024   \n",
              "1    answer_relevancy  0.852605                                    0.945499   \n",
              "2      context_recall  0.650000                                    0.741667   \n",
              "3   context_precision  0.758333                                    0.711185   \n",
              "4  answer_correctness  0.551982                                    0.552914   \n",
              "\n",
              "      Delta  \n",
              "0  0.086534  \n",
              "1  0.092894  \n",
              "2  0.091667  \n",
              "3 -0.047149  \n",
              "4  0.000932  "
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_original = pd.DataFrame(list(results.items()), columns=['Metric', 'Baseline'])\n",
        "df_comparison = pd.DataFrame(list(advanced_retrieval_results.items()), columns=['Metric', 'MultiQueryRetriever with Document Stuffing'])\n",
        "\n",
        "df_merged = pd.merge(df_original, df_comparison, on='Metric')\n",
        "\n",
        "df_merged['Delta'] = df_merged['MultiQueryRetriever with Document Stuffing'] - df_merged['Baseline']\n",
        "\n",
        "df_merged"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJKEOLNs5v0R"
      },
      "source": [
        "## Task 4: Testing OpenAI's Claim\n",
        "\n",
        "Now that we've seen how our retriever can impact the performance of our RAG pipeline - let's see how changing our embedding model impacts performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM4KRhJYEL-h"
      },
      "source": [
        "####🏗️ Activity #2:\n",
        "\n",
        "Please provide markdown, or code comments, to explain which each of the following steps are doing!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gv_tv4w86bPb"
      },
      "outputs": [],
      "source": [
        "new_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JPe1_Jx6Rnw"
      },
      "outputs": [],
      "source": [
        "vector_store = Qdrant.from_documents(\n",
        "    documents,\n",
        "    new_embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"PMarca Blogs - TE3 - MQR\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-HuozNf6muZ"
      },
      "outputs": [],
      "source": [
        "new_retriever = vector_store.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6Tyc3ZY7Km2"
      },
      "outputs": [],
      "source": [
        "new_advanced_retriever = MultiQueryRetriever.from_llm(retriever=new_retriever, llm=primary_qa_llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5QSJIhm7SKr"
      },
      "outputs": [],
      "source": [
        "new_retrieval_chain = create_retrieval_chain(new_advanced_retriever, document_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBVjl1UK7fd7"
      },
      "outputs": [],
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = new_retrieval_chain.invoke({\"input\" : question})\n",
        "  answers.append(response[\"answer\"])\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTBrs0zr7iyG"
      },
      "outputs": [],
      "source": [
        "new_response_dataset_advanced_retrieval = Dataset.from_dict({\n",
        "    \"question\" : test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : test_groundtruths\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "399f6ec046c34c26818a07c5efc6845a",
            "7f82e0a3c3684460b8dda773d283b535",
            "cfa01f60b62f4a88806d85cee5ac0fa6",
            "38988d3f6f5f4de3b3d4be7fec89c3c7",
            "87bd0ad74d4345dea4b409d64524f6e7",
            "8cb506949697432db061878397d196f1",
            "e7831a581d024e3ebb4026a89ceef127",
            "18701fc64eb44d26b8aa1ae0af64d09f",
            "a6581091161c489d877c2cfec432f6ae",
            "42dcc945d1624f69b63bed2fa52cc4fa",
            "5524289f1e594a5eac60ee29d9f4249c"
          ]
        },
        "id": "hG5h-D8n7sZp",
        "outputId": "6760b49b-4576-4bee-e61a-293df24e2bc3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "399f6ec046c34c26818a07c5efc6845a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "new_advanced_retrieval_results = evaluate(new_response_dataset_advanced_retrieval, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uHdcpsZ76kj",
        "outputId": "53a4f4ef-13ce-4a89-a06e-6c255ed3c025"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.8658, 'answer_relevancy': 0.9454, 'context_recall': 0.6792, 'context_precision': 0.8472, 'answer_correctness': 0.5055}"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_advanced_retrieval_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s4TyaCUQ79Ke",
        "outputId": "c496266c-bf4a-4a3a-cd27-1d8abbf5bdb3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_merged\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Metric\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"answer_relevancy\",\n          \"answer_correctness\",\n          \"context_recall\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ADA + Baseline\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11820882731030606,\n        \"min\": 0.5519819867147012,\n        \"max\": 0.8526045555079783,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8526045555079783,\n          0.5519819867147012,\n          0.65\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ADA + MQR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14015826154350428,\n        \"min\": 0.552913718421707,\n        \"max\": 0.9454990446409471,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9454990446409471,\n          0.552913718421707,\n          0.7416666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TE3 + MQR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17614304618077442,\n        \"min\": 0.5055253153960619,\n        \"max\": 0.9454351556818363,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9454351556818363,\n          0.5055253153960619,\n          0.6791666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ADA + MQR -> TE3 + MQR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10226616721316409,\n        \"min\": -0.0625,\n        \"max\": 0.15380952380952395,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -6.388895911080272e-05,\n          -0.047388403025645065,\n          -0.0625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Baseline -> TE3 + MQR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10550303141776424,\n        \"min\": -0.04645667131863929,\n        \"max\": 0.24034313725490208,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.09283060017385802,\n          -0.04645667131863929,\n          0.029166666666666563\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_merged"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f89330a2-dd7d-47f6-8333-dd5cfbc9ce87\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>ADA + Baseline</th>\n",
              "      <th>ADA + MQR</th>\n",
              "      <th>TE3 + MQR</th>\n",
              "      <th>ADA + MQR -&gt; TE3 + MQR</th>\n",
              "      <th>Baseline -&gt; TE3 + MQR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>faithfulness</td>\n",
              "      <td>0.625490</td>\n",
              "      <td>0.712024</td>\n",
              "      <td>0.865833</td>\n",
              "      <td>0.153810</td>\n",
              "      <td>0.240343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>answer_relevancy</td>\n",
              "      <td>0.852605</td>\n",
              "      <td>0.945499</td>\n",
              "      <td>0.945435</td>\n",
              "      <td>-0.000064</td>\n",
              "      <td>0.092831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.741667</td>\n",
              "      <td>0.679167</td>\n",
              "      <td>-0.062500</td>\n",
              "      <td>0.029167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.758333</td>\n",
              "      <td>0.711185</td>\n",
              "      <td>0.847174</td>\n",
              "      <td>0.135990</td>\n",
              "      <td>0.088841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.551982</td>\n",
              "      <td>0.552914</td>\n",
              "      <td>0.505525</td>\n",
              "      <td>-0.047388</td>\n",
              "      <td>-0.046457</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f89330a2-dd7d-47f6-8333-dd5cfbc9ce87')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f89330a2-dd7d-47f6-8333-dd5cfbc9ce87 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f89330a2-dd7d-47f6-8333-dd5cfbc9ce87');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fd17deab-6c9a-4f83-ae9c-7431a8afb1c5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fd17deab-6c9a-4f83-ae9c-7431a8afb1c5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fd17deab-6c9a-4f83-ae9c-7431a8afb1c5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_65ea0745-b0ec-4123-8544-ab9bc81e100b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_merged')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_65ea0745-b0ec-4123-8544-ab9bc81e100b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_merged');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "               Metric  ADA + Baseline  ADA + MQR  TE3 + MQR  \\\n",
              "0        faithfulness        0.625490   0.712024   0.865833   \n",
              "1    answer_relevancy        0.852605   0.945499   0.945435   \n",
              "2      context_recall        0.650000   0.741667   0.679167   \n",
              "3   context_precision        0.758333   0.711185   0.847174   \n",
              "4  answer_correctness        0.551982   0.552914   0.505525   \n",
              "\n",
              "   ADA + MQR -> TE3 + MQR  Baseline -> TE3 + MQR  \n",
              "0                0.153810               0.240343  \n",
              "1               -0.000064               0.092831  \n",
              "2               -0.062500               0.029167  \n",
              "3                0.135990               0.088841  \n",
              "4               -0.047388              -0.046457  "
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_baseline = pd.DataFrame(list(results.items()), columns=['Metric', 'ADA + Baseline'])\n",
        "df_original = pd.DataFrame(list(advanced_retrieval_results.items()), columns=['Metric', 'ADA + MQR'])\n",
        "df_comparison = pd.DataFrame(list(new_advanced_retrieval_results.items()), columns=['Metric', 'TE3 + MQR'])\n",
        "\n",
        "df_merged = pd.merge(df_original, df_comparison, on='Metric')\n",
        "df_merged = pd.merge(df_baseline, df_merged, on=\"Metric\")\n",
        "\n",
        "df_merged['ADA + MQR -> TE3 + MQR'] = df_merged['TE3 + MQR'] - df_merged['ADA + MQR']\n",
        "df_merged['Baseline -> TE3 + MQR'] = df_merged['TE3 + MQR'] - df_merged['ADA + Baseline']\n",
        "\n",
        "df_merged"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRmkcMrxC4Me"
      },
      "source": [
        "####❓ Question #4:\n",
        "\n",
        "Do you think, in your opinion, `text-embedding-3-small` is significantly better than `ada`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOciJLABDBnA"
      },
      "source": [
        "## BONUS ACTIVITY: Using a Better Generator\n",
        "\n",
        "Now that we've seen how much more effective a better Retrieval pipeline is, let's look at what impact a better(?) Generator is!\n",
        "\n",
        "Adapt the above `TE3 + MQR` pipeline to use `GPT-4o` and compare the results below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MY8l2EksDH43"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05390d20f1b445b5b02529ee7a99f6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_589c2004f5504a239615dec8671785d0",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25d3337c457f4c748ed8bf78f5a27fe8",
            "value": 100
          }
        },
        "05ab48866b5d49df9567ce9cbda5ee2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49c1ef316e404052a7c8528781db3f9a",
              "IPY_MODEL_2dcb3e2fdf164e35a27a79cfae65933a",
              "IPY_MODEL_202f4244384a4501bfc1ffa50af96a1f"
            ],
            "layout": "IPY_MODEL_d93698b0506743ff98fdb998cfb7080a"
          }
        },
        "1317f4e20e1c4574a360345b427c3e8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92ef10fab64c4f40a93da3d31b572016",
            "placeholder": "​",
            "style": "IPY_MODEL_3b43c3f561e34d019007ac9a0125b28d",
            "value": " 1248/1248 [00:46&lt;00:00, 13.97it/s]"
          }
        },
        "18701fc64eb44d26b8aa1ae0af64d09f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19acd28bfa2e4a7a83bc42faea5de770": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d43002974f24e8a8b6961cddc04ce47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fb5a4b71deb406fa2f342c88b9e4e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e1d22c19aff4c768d643c249e425d00",
            "placeholder": "​",
            "style": "IPY_MODEL_3a498872a68049329b4d206629b9b3bf",
            "value": "embedding nodes: 100%"
          }
        },
        "202f4244384a4501bfc1ffa50af96a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a10a7577a99b4683a1d59a09d88f93a1",
            "placeholder": "​",
            "style": "IPY_MODEL_444bc7dae1aa4e098b79655428599310",
            "value": " 20/20 [01:04&lt;00:00, 10.00s/it]"
          }
        },
        "25d3337c457f4c748ed8bf78f5a27fe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2aa53858803d4ad39113009d86dd67fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "2dcb3e2fdf164e35a27a79cfae65933a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60a663f8736a43bcb47ac6c5f37ec597",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6edc46811064de2b74a6a477c4a44b7",
            "value": 20
          }
        },
        "31064d2adec14238a609d3f9791c64f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32514310070a426ea247c9f1bc66b630": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e7520df71de40e0af5589b6aeb95171",
              "IPY_MODEL_05390d20f1b445b5b02529ee7a99f6d6",
              "IPY_MODEL_3380693903474d2585638f7e3458fcd6"
            ],
            "layout": "IPY_MODEL_1d43002974f24e8a8b6961cddc04ce47"
          }
        },
        "3380693903474d2585638f7e3458fcd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31064d2adec14238a609d3f9791c64f3",
            "placeholder": "​",
            "style": "IPY_MODEL_4f482b8ce7a54c1787394fb7d90391a0",
            "value": " 100/100 [00:33&lt;00:00,  1.55s/it]"
          }
        },
        "356b929fa8dc42538767c58dcce12217": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37ec9b5c847749439d7c155ac3b1ec68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89a7c333d0b241169dc29ed998b2c9c4",
            "max": 1248,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88c8557741734e59a6099bb5fa260f6e",
            "value": 1248
          }
        },
        "38988d3f6f5f4de3b3d4be7fec89c3c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42dcc945d1624f69b63bed2fa52cc4fa",
            "placeholder": "​",
            "style": "IPY_MODEL_5524289f1e594a5eac60ee29d9f4249c",
            "value": " 100/100 [00:45&lt;00:00,  1.68s/it]"
          }
        },
        "399f6ec046c34c26818a07c5efc6845a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f82e0a3c3684460b8dda773d283b535",
              "IPY_MODEL_cfa01f60b62f4a88806d85cee5ac0fa6",
              "IPY_MODEL_38988d3f6f5f4de3b3d4be7fec89c3c7"
            ],
            "layout": "IPY_MODEL_87bd0ad74d4345dea4b409d64524f6e7"
          }
        },
        "3a498872a68049329b4d206629b9b3bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b43c3f561e34d019007ac9a0125b28d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e7520df71de40e0af5589b6aeb95171": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97abe811c89c44dcacd7e39074d22546",
            "placeholder": "​",
            "style": "IPY_MODEL_87a3d4b2ed5f4f1ca895c6a1981eb847",
            "value": "Evaluating: 100%"
          }
        },
        "40343486e3ea4e5fae55b5a528f139d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42dcc945d1624f69b63bed2fa52cc4fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "444bc7dae1aa4e098b79655428599310": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49c1ef316e404052a7c8528781db3f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19acd28bfa2e4a7a83bc42faea5de770",
            "placeholder": "​",
            "style": "IPY_MODEL_356b929fa8dc42538767c58dcce12217",
            "value": "Generating: 100%"
          }
        },
        "4cefefc6cf714a68924e1b8d5e59aba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c2b92989d7448e9bf65306c4f2f7d93",
            "placeholder": "​",
            "style": "IPY_MODEL_a34b3906cd514234a115c7bf6757ca9d",
            "value": "Evaluating: 100%"
          }
        },
        "4f482b8ce7a54c1787394fb7d90391a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5524289f1e594a5eac60ee29d9f4249c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "589c2004f5504a239615dec8671785d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c2b92989d7448e9bf65306c4f2f7d93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60a663f8736a43bcb47ac6c5f37ec597": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e1d22c19aff4c768d643c249e425d00": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f82e0a3c3684460b8dda773d283b535": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cb506949697432db061878397d196f1",
            "placeholder": "​",
            "style": "IPY_MODEL_e7831a581d024e3ebb4026a89ceef127",
            "value": "Evaluating: 100%"
          }
        },
        "831b4dab6ff94d239d2824d390e01308": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cefefc6cf714a68924e1b8d5e59aba9",
              "IPY_MODEL_fd7f5542a22d44388dda12ca19443a1f",
              "IPY_MODEL_93bf9b194c04460abffa192c19bcf67b"
            ],
            "layout": "IPY_MODEL_83985f58744a46cfbd001ce5957f3e4a"
          }
        },
        "83985f58744a46cfbd001ce5957f3e4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87a3d4b2ed5f4f1ca895c6a1981eb847": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87bd0ad74d4345dea4b409d64524f6e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c8557741734e59a6099bb5fa260f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89a7c333d0b241169dc29ed998b2c9c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cb506949697432db061878397d196f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92ef10fab64c4f40a93da3d31b572016": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93bf9b194c04460abffa192c19bcf67b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cee2268aa21643e6ad77117c67ec1600",
            "placeholder": "​",
            "style": "IPY_MODEL_c79f28da88f44d69aa87905c089df333",
            "value": " 100/100 [00:44&lt;00:00,  1.69s/it]"
          }
        },
        "97abe811c89c44dcacd7e39074d22546": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a03fefb9fa5a40ff947dc4ccd3c80318": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a10a7577a99b4683a1d59a09d88f93a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a34b3906cd514234a115c7bf6757ca9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6581091161c489d877c2cfec432f6ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c79f28da88f44d69aa87905c089df333": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cee2268aa21643e6ad77117c67ec1600": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfa01f60b62f4a88806d85cee5ac0fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18701fc64eb44d26b8aa1ae0af64d09f",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6581091161c489d877c2cfec432f6ae",
            "value": 100
          }
        },
        "d93698b0506743ff98fdb998cfb7080a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6edc46811064de2b74a6a477c4a44b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7831a581d024e3ebb4026a89ceef127": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f75fdd56268a4b83a7fb7e4a3b2cce82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1fb5a4b71deb406fa2f342c88b9e4e1d",
              "IPY_MODEL_37ec9b5c847749439d7c155ac3b1ec68",
              "IPY_MODEL_1317f4e20e1c4574a360345b427c3e8a"
            ],
            "layout": "IPY_MODEL_2aa53858803d4ad39113009d86dd67fc"
          }
        },
        "fd7f5542a22d44388dda12ca19443a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a03fefb9fa5a40ff947dc4ccd3c80318",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40343486e3ea4e5fae55b5a528f139d8",
            "value": 100
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
